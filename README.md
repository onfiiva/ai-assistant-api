# AI Assistant API

[English](#english) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](#Ñ€ÑƒÑÑĞºĞ¸Ğ¹)

- [ğŸ³ Installation](#-docker-setup--running)
- [ğŸ³ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°](#-docker-ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°-Ğ¸-Ğ·Ğ°Ğ¿ÑƒÑĞº)

â¸»

## English

The ai-assistant-api project allows interaction with LLMs (Large Language Models) via API.
Supported models:
- [OpenAI](https://openai.com)
- [Gemini](https://gemini.google.com)
- [Ollama](https://ollama.com) (used: [mistral:7b-instruct-q4_K_M](https://ollama.com/library/mistral:7b-instruct-q4_K_M))
- [Qwen3](https://qwen.ai/) (used: [Qwen3-4B-VL-Instruct](https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct))

With this project, you can:
- Send requests to LLMs (sync, async and via agent)
- Use RAG (retrieval-augmented generation)
- Experiment with generation parameters (temperature, top_p, max_tokens, etc.)
- Track job status via async inference API
- Control request timeouts
- Save responses in JSON format for analysis and testing
- Switch between multiple LLM providers in the same request
- Filter system/forbidden commands and sanitize user input
- Track and log malicious requests
- Apply rate limiting per user/admin
- Embed documents, store them in a vector database (Qdrant), and perform semantic search
- Work with multi-language content and large documents by chunking
- Swagger UI with JWT authorization support
- Use async inference workers with job queue and heartbeat monitoring
- Simple LoRa

â¸»

### ğŸ“ Project Structure
```bash
ai-assistant-api/
â”œâ”€â”€ docker-compose.yaml                   # Docker Compose configuration to run all project services
â”œâ”€â”€ models                                # Directory for storing machine learning models
â”‚   â””â”€â”€ qwen3-vl-4b-instruct              # Specific model Qwen3-VL-4B
â”‚       â”œâ”€â”€ chat_template.json            # Chat templates for the model
â”‚       â”œâ”€â”€ config.json                   # Main model configuration
â”‚       â”œâ”€â”€ generation_config.json        # Text/video generation settings
â”‚       â”œâ”€â”€ merges.txt                    # Token merges file (for tokenizer)
â”‚       â”œâ”€â”€ model-00001-of-00002.safetensors # Model weights (part 1)
â”‚       â”œâ”€â”€ model-00002-of-00002.safetensors # Model weights (part 2)
â”‚       â”œâ”€â”€ model.safetensors.index.json  # Model weights index
â”‚       â”œâ”€â”€ preprocessor_config.json      # Data preprocessor configuration
â”‚       â”œâ”€â”€ README.md                     # Model documentation
â”‚       â”œâ”€â”€ tokenizer_config.json         # Tokenizer configuration
â”‚       â”œâ”€â”€ tokenizer.json                # Model tokenizer
â”‚       â”œâ”€â”€ video_preprocessor_config.json # Video preprocessor configuration
â”‚       â””â”€â”€ vocab.json                    # Model vocabulary
â”œâ”€â”€ README.md                             # General project documentation
â””â”€â”€ services                              # Project services directory
    â”œâ”€â”€ api                               # API service (FastAPI)
    â”‚   â”œâ”€â”€ alembic                       # Database migration configuration via Alembic
    â”‚   â”‚   â”œâ”€â”€ env.py                    # Main Alembic environment script
    â”‚   â”‚   â”œâ”€â”€ README                    # Alembic documentation
    â”‚   â”‚   â”œâ”€â”€ script.py.mako            # Migration script template
    â”‚   â”‚   â””â”€â”€ versions                  # Migration history
    â”‚   â”œâ”€â”€ alembic.ini                   # Alembic configuration for DB connection
    â”‚   â”œâ”€â”€ app                            # Main application code
    â”‚   â”‚   â”œâ”€â”€ agents                    # Agent logic (AI/LLM)
    â”‚   â”‚   â”‚   â”œâ”€â”€ actions.py            # Definition of agent actions
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # Agent configuration
    â”‚   â”‚   â”‚   â”œâ”€â”€ memory                # Agent memory modules
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py           # Base memory class
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py      # In-memory storage
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis_async.py    # Asynchronous Redis memory
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py          # Synchronous Redis memory
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ summarize.py      # Memory summarization module
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ vector_memory.py  # Vector memory
    â”‚   â”‚   â”‚   â”œâ”€â”€ react                  # Reactive agents
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ agent.py          # Reactive agent logic
    â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py            # Pydantic schemas for agents
    â”‚   â”‚   â”‚   â”œâ”€â”€ services              # Auxiliary agent services
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ summary.py        # Summarization service
    â”‚   â”‚   â”‚   â”œâ”€â”€ state.py              # Agent state storage
    â”‚   â”‚   â”‚   â””â”€â”€ tools                 # Agent tools
    â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py       # Tools module initialization
    â”‚   â”‚   â”‚       â”œâ”€â”€ actions
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ execute.py    # Execute agent actions
    â”‚   â”‚   â”‚       â”œâ”€â”€ base.py           # Base agent tools
    â”‚   â”‚   â”‚       â”œâ”€â”€ external_api.py   # Working with external APIs
    â”‚   â”‚   â”‚       â”œâ”€â”€ registry.py       # Agent tool registry
    â”‚   â”‚   â”‚       â”œâ”€â”€ search.py         # Agent search functions
    â”‚   â”‚   â”‚       â”œâ”€â”€ summary.py        # Agent data summarization
    â”‚   â”‚   â”‚       â”œâ”€â”€ validation.py     # Input data validation
    â”‚   â”‚   â”‚       â”œâ”€â”€ vector_search_async.py # Asynchronous vector search
    â”‚   â”‚   â”‚       â””â”€â”€ vector_search.py  # Synchronous vector search
    â”‚   â”‚   â”œâ”€â”€ api                        # FastAPI endpoints
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py             # Endpoints for agents
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py               # Authorization and authentication
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat_async.py         # Asynchronous chat
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py               # Synchronous chat
    â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py         # Endpoints for embeddings
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py          # Model inference endpoints
    â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Data ingestion for models
    â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning.py # LLM instruction tuning
    â”‚   â”‚   â”‚   â”œâ”€â”€ search.py             # Search endpoints
    â”‚   â”‚   â”‚   â””â”€â”€ smart_chat.py         # Smart chat endpoint
    â”‚   â”‚   â”œâ”€â”€ container.py              # DI container for the application
    â”‚   â”‚   â”œâ”€â”€ core                        # Application core
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # Core configuration
    â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py            # Application logging
    â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py              # Redis configuration
    â”‚   â”‚   â”‚   â”œâ”€â”€ security.py           # Security and encryption
    â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py             # Timing utilities
    â”‚   â”‚   â”‚   â”œâ”€â”€ tokens.py             # Token handling
    â”‚   â”‚   â”‚   â””â”€â”€ vault.py              # Secret vault integration
    â”‚   â”‚   â”œâ”€â”€ dependencies               # FastAPI dependencies
    â”‚   â”‚   â”‚   â”œâ”€â”€ agent_params.py       # Agent parameters
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py               # Authorization dependencies
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py          # Inference dependencies
    â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limit.py         # Request rate limiting
    â”‚   â”‚   â”‚   â”œâ”€â”€ security.py           # Endpoint security
    â”‚   â”‚   â”‚   â”œâ”€â”€ user.py               # User dependencies
    â”‚   â”‚   â”‚   â””â”€â”€ validation.py         # General validation
    â”‚   â”‚   â”œâ”€â”€ embeddings                 # Embedding management
    â”‚   â”‚   â”‚   â”œâ”€â”€ clients               # Embedding clients
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ client.py         # Base embedding client
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_client.py  # Gemini client
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openai_client.py  # OpenAI client
    â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py            # Embedding factory
    â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py            # Embedding data schemas
    â”‚   â”‚   â”‚   â”œâ”€â”€ service.py            # Embedding service
    â”‚   â”‚   â”‚   â”œâ”€â”€ similarity.py         # Similarity calculations
    â”‚   â”‚   â”‚   â””â”€â”€ vector_store.py       # Vector storage
    â”‚   â”‚   â”œâ”€â”€ inference                  # Model inference module
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference_repository.py       # Inference repository
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference_service.py  # Inference service
    â”‚   â”‚   â”‚   â””â”€â”€ workers               # Inference workers
    â”‚   â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py # Asynchronous worker
    â”‚   â”‚   â”‚       â”œâ”€â”€ inference_worker.py       # Synchronous worker
    â”‚   â”‚   â”‚       â”œâ”€â”€ job_handler       # Job handlers
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ base.py       # Base handler template
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llm_handler.py        # LLM handler
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ react_handler.py      # ReAct agent handler
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ smart_orchestration_handler.py        # Orchestrator handler
    â”‚   â”‚   â”‚       â””â”€â”€ worker_main.py   # Main worker process
    â”‚   â”‚   â”œâ”€â”€ infra                    # Infrastructure
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py           # Data chunking
    â”‚   â”‚   â”‚   â”œâ”€â”€ db                   # Database utilities
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models           # DB models
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py      # Base model
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models.py    # Core collection models
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user_model.py  # User model
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pg.py              # PostgreSQL connection
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qdrant.py          # Qdrant connection
    â”‚   â”‚   â”‚   â””â”€â”€ pdf_loader.py          # PDF loading and processing
    â”‚   â”‚   â”œâ”€â”€ llm                         # LLM logic
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapters               # Adapters for different LLMs
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ client.py          # Base client
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ geminiAdapter.py   # Gemini client
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ollamaAdapter.py   # Ollama client
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py   # OpenAI client
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qwen3vlAdapter.py  # Qwen3 4B VL Instruct client
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py            # LLM configuration
    â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py           # LLM factory
    â”‚   â”‚   â”‚   â”œâ”€â”€ filter.py            # LLM filter
    â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py        # Data normalizer
    â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py            # LLM runner
    â”‚   â”‚   â”‚   â”œâ”€â”€ sanitizer.py         # Security checks
    â”‚   â”‚   â”‚   â””â”€â”€ schemas.py           # LLM schemas (input/output/gen config)
    â”‚   â”‚   â”œâ”€â”€ main.py                     # FastAPI application entry point
    â”‚   â”‚   â”œâ”€â”€ middlewares                # FastAPI middlewares
    â”‚   â”‚   â”‚   â”œâ”€â”€ body.py                # Request body processing
    â”‚   â”‚   â”‚   â”œâ”€â”€ observability.py       # Metrics and observability
    â”‚   â”‚   â”‚   â”œâ”€â”€ prometheus.py          # Export metrics to Prometheus
    â”‚   â”‚   â”‚   â”œâ”€â”€ timings.py             # Request timing
    â”‚   â”‚   â”‚   â””â”€â”€ tokens.py              # Token processing middleware
    â”‚   â”‚   â”œâ”€â”€ models                     # Models
    â”‚   â”‚   â”‚   â””â”€â”€ user.py                # User model
    â”‚   â”‚   â”œâ”€â”€ schemas                    # Pydantic schemas
    â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py               # Agent schemas
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                # Auth/register schemas
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py                # Base request schemas
    â”‚   â”‚   â”‚   â””â”€â”€ inference.py           # Inference schemas
    â”‚   â”‚   â”œâ”€â”€ services                   # Business logic services
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py        # Auth service
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat_service.py        # Chat service
    â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py           # Data ingestion service
    â”‚   â”‚   â”‚   â”œâ”€â”€ orchestration          # LLM and agent orchestration
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ classifier.py      # One-shot or complex request classifier
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.py    # Orchestrator between agent and simple LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ prompts                # LLM prompts
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ classifier_prompt.py  # Classification prompt
    â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py         # Retrieval-Augmented Generation service
    â”‚   â”‚   â”œâ”€â”€ startup.py                 # Application initialization
    â”‚   â”‚   â””â”€â”€ validators                 # Validators
    â”‚   â”‚       â”œâ”€â”€ agent.py               # Agent validation
    â”‚   â”‚       â”œâ”€â”€ generation.py          # Generation config validation
    â”‚   â”‚       â”œâ”€â”€ provider.py            # Provider validation
    â”‚   â”‚       â””â”€â”€ timeout.py             # Timeout validation
    â”‚   â”œâ”€â”€ Dockerfile                      # Dockerfile for API service
    â”‚   â”œâ”€â”€ prometheus.yaml                 # Prometheus monitoring configuration
    â”‚   â”œâ”€â”€ reflection.md                   # Service documentation/reflection
    â”‚   â””â”€â”€ requirements.txt                # Python project dependencies
    â””â”€â”€ qwen                                # Separate Qwen service
        â”œâ”€â”€ Dockerfile.qwen                 # Dockerfile for Qwen service
        â”œâ”€â”€ inference_service.py            # Model inference launcher
        â””â”€â”€ main.py                         # Main file for Qwen service
```

â¸»

### ğŸ³ Docker Setup & Running
Hint: If you are happy owner of Apple Silicon, launch Ollama/Qwen/other open source models locally, NOT via Docker

1.	Build and run containers:
```bash
docker-compose up --build
```
2.	API available at:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	Vault KV setup:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  QWEN3_VL_BASE_URL="http://host.docker.internal:8000" \
  ALLOWED_PROVIDERS='["openai","gemini","ollama","qwen3vl"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```
5. Qwen3 Inference API launch:
- If Apple Silicon:
```bash
uvicorn services.qwen.main:app --reload
```
- If your hardware have drivers in Docker - uncomment docker compose qwen block and change Vault secret QWEN3_VL_BASE_URL and model path to "/models/qwen3v1"

â¸»

### ğŸ”‘ Environment Variables (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```

â¸»

### ğŸ’¡ Endpoints

/auth
- POST /auth/login â€” login user and return JWT token
- POST /auth/register â€” register a new user (admin only) and return JWT token

/chat
- POST /chat/ â€” sync LLM call
- POST /chat/rag â€” sync RAG call
- POST /chat/async â€” async LLM call, returns job_id
- POST /chat/rag/async â€” async RAG call, returns job_id

/chat/smart
- POST /chat/smart/run - process a single-shot or complex prompt via agent or raw LLM

/agents
- POST /agents/run â€” run an agent with a goal, returns job_id
- GET /agents/{job_id} â€” get agent job status and step history
- GET /agents/tools â€” list available tools for the agent

/embeddings
- POST /embeddings/search â€” semantic search, returns top-k results

/ingestion
- POST /ingestion/ingest â€” ingest PDF documents into vector DB with embeddings

/search
- GET /search/ â€” search pre-ingested embeddings, returns top-k matches

/inference
- POST /inference/ â€” create async inference job
- GET /inference/{job_id} â€” get status and result/error of async job

â¸»

### âš™ï¸ Async Inference Worker

#### Purpose
Handles asynchronous execution of LLM requests. Users do not need to wait for LLM to finish in real-time â€” they can fetch results later using a job_id.

#### Workflow
1.	Job creation: user sends a request to /chat/async or /chat/rag/async
2.	Job queue: jobs enter a Redis-backed queue respecting rate limits and LLM load
3.	Workers: run as separate processes/containers and process jobs:
- Send request to LLM (OpenAI/Gemini)
- Normalize, filter, and log responses
- Save result/error back to Redis
4.	Heartbeat: workers send periodic heartbeat signals
5.	Fetching results: GET /inference/{job_id} returns:
- status: pending, completed, error
- result (if ready)
- error message (if any)

#### Usage
- Run a worker:
```bash
python -m app.inference.workers.worker_main
```
- Multiple workers can run simultaneously
- Load is balanced via job queue
- Works with rate-limiting to prevent overloading LLM

#### Related Endpoints
- POST /chat/async â€” create async LLM job
- POST /chat/rag/async â€” create async RAG job
- GET /inference/{job_id} â€” fetch job result/status

â¸»

### ğŸ“š Resources
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference/introduction)
- [Gemini API Documentation](https://ai.google.dev/gemini-api/docs?hl=en)
- [HuggingFace](https://huggingface.co/)
- [Ollama](https://ollama.com)


## Ğ ÑƒÑÑĞºĞ¸Ğ¹

ĞŸÑ€Ğ¾ĞµĞºÑ‚ ai-assistant-api Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ LLM (Large Language Models â€” Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸) Ñ‡ĞµÑ€ĞµĞ· API.
ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
- [OpenAI](https://openai.com)
- [Gemini](https://gemini.google.com)
- [Ollama](https://ollama.com) (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ°: [mistral:7b-instruct-q4_K_M](https://ollama.com/library/mistral:7b-instruct-q4_K_M))
- [Qwen3](https://qwen.ai/) (Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ°: [Qwen3-4B-VL-Instruct](https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct))

Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ:
- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº LLM (ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾, Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ³ĞµĞ½Ñ‚Ğ°)
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ RAG (retrieval-augmented generation â€” Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ°)
- Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (temperature, top_p, max_tokens Ğ¸ Ğ´Ñ€.)
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ API Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ LLM-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ
- Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ/Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ Ğ¾Ñ‡Ğ¸Ñ‰Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ²Ğ²Ğ¾Ğ´
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ/Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
- Ğ’ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¸Ñ… Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ‘Ğ” (Qdrant) Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°Ñ Ğ¸Ñ… Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Swagger UI Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· JWT
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ñ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ heartbeat
- ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ LoRa

â¸»

### ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
```bash
ai-assistant-api/
â”œâ”€â”€ docker-compose.yaml                   # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Docker Compose Ğ´Ğ»Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ²ÑĞµÑ… ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
â”œâ”€â”€ models                                # ĞšĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ğ´Ğ»Ñ Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹ Ğ¼Ğ°ÑˆĞ¸Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ¾Ğ±ÑƒÑ‡ĞµĞ½Ğ¸Ñ
â”‚   â””â”€â”€ qwen3-vl-4b-instruct              # ĞšĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Qwen3-VL-4B
â”‚       â”œâ”€â”€ chat_template.json            # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½Ñ‹ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ¾Ğ² Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚       â”œâ”€â”€ config.json                   # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚       â”œâ”€â”€ generation_config.json        # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ‚ĞµĞºÑÑ‚Ğ°/Ğ²Ğ¸Ğ´ĞµĞ¾
â”‚       â”œâ”€â”€ merges.txt                    # Ğ¤Ğ°Ğ¹Ğ» Ñ Ğ¾Ğ±ÑŠĞµĞ´Ğ¸Ğ½ĞµĞ½Ğ¸ÑĞ¼Ğ¸ Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² (Ğ´Ğ»Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°)
â”‚       â”œâ”€â”€ model-00001-of-00002.safetensors # Ğ’ĞµÑÑ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ñ‡Ğ°ÑÑ‚ÑŒ 1)
â”‚       â”œâ”€â”€ model-00002-of-00002.safetensors # Ğ’ĞµÑÑ‹ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ (Ñ‡Ğ°ÑÑ‚ÑŒ 2)
â”‚       â”œâ”€â”€ model.safetensors.index.json  # Ğ˜Ğ½Ğ´ĞµĞºÑ Ğ²ĞµÑĞ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚       â”œâ”€â”€ preprocessor_config.json      # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ° Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚       â”œâ”€â”€ README.md                     # Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚       â”œâ”€â”€ tokenizer_config.json         # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€Ğ°
â”‚       â”œâ”€â”€ tokenizer.json                # Ğ¢Ğ¾ĞºĞµĞ½Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚       â”œâ”€â”€ video_preprocessor_config.json # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¿Ñ€ĞµĞ¿Ñ€Ğ¾Ñ†ĞµÑÑĞ¾Ñ€Ğ°
â”‚       â””â”€â”€ vocab.json                    # Ğ¡Ğ»Ğ¾Ğ²Ğ°Ñ€ÑŒ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”œâ”€â”€ README.md                             # ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
â””â”€â”€ services                              # ĞšĞ°Ñ‚Ğ°Ğ»Ğ¾Ğ³ Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ°Ğ¼Ğ¸ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
    â”œâ”€â”€ api                               # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ API (FastAPI)
    â”‚   â”œâ”€â”€ alembic                       # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹ Ğ‘Ğ” Ñ‡ĞµÑ€ĞµĞ· Alembic
    â”‚   â”‚   â”œâ”€â”€ env.py                    # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞºÑ€Ğ¸Ğ¿Ñ‚ ÑÑ€ĞµĞ´Ñ‹ Alembic
    â”‚   â”‚   â”œâ”€â”€ README                    # Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Alembic
    â”‚   â”‚   â”œâ”€â”€ script.py.mako            # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ² Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â””â”€â”€ versions                  # Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
    â”‚   â”œâ”€â”€ alembic.ini                   # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Alembic Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ñ Ğº Ğ‘Ğ”
    â”‚   â”œâ”€â”€ app                            # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ´ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â”œâ”€â”€ agents                    # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² (AI/LLM)
    â”‚   â”‚   â”‚   â”œâ”€â”€ actions.py            # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ memory                # ĞœĞ¾Ğ´ÑƒĞ»Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py           # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py      # ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ² Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²ĞºĞµ
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis_async.py    # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Ñ‡ĞµÑ€ĞµĞ· Redis
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py          # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Redis
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ summarize.py      # ĞœĞ¾Ğ´ÑƒĞ»ÑŒ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ vector_memory.py  # Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
    â”‚   â”‚   â”‚   â”œâ”€â”€ react                  # Ğ ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ñ‹Ğµ Ğ°Ğ³ĞµĞ½Ñ‚Ñ‹
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ agent.py          # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ñ€ĞµĞ°ĞºÑ‚Ğ¸Ğ²Ğ½Ğ¾Ğ³Ğ¾ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py            # Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ services              # Ğ’ÑĞ¿Ğ¾Ğ¼Ğ¾Ğ³Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ ÑĞµÑ€Ğ²Ğ¸ÑÑ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ summary.py        # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ state.py              # Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â””â”€â”€ tools                 # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py       # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ´ÑƒĞ»Ñ tools
    â”‚   â”‚   â”‚       â”œâ”€â”€ actions
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ execute.py    # Ğ˜ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ base.py           # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ external_api.py   # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ğ¼Ğ¸ API
    â”‚   â”‚   â”‚       â”œâ”€â”€ registry.py       # Ğ ĞµĞµÑÑ‚Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ search.py         # ĞŸĞ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğµ Ñ„ÑƒĞ½ĞºÑ†Ğ¸Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ summary.py        # Ğ¡ÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚       â”œâ”€â”€ validation.py     # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ° ĞºĞ¾Ñ€Ñ€ĞµĞºÑ‚Ğ½Ğ¾ÑÑ‚Ğ¸ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    â”‚   â”‚   â”‚       â”œâ”€â”€ vector_search_async.py # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
    â”‚   â”‚   â”‚       â””â”€â”€ vector_search.py  # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
    â”‚   â”‚   â”œâ”€â”€ api                        # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ FastAPI
    â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py             # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py               # ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat_async.py         # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py               # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚
    â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py         # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py          # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py          # Ğ˜Ğ½Ğ³ĞµÑÑ‚ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ´Ğ»Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning.py # ĞŸĞ¾Ğ´ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ğ¹ LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ search.py             # ĞŸĞ¾Ğ¸ÑĞºĞ¾Ğ²Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹
    â”‚   â”‚   â”‚   â””â”€â”€ smart_chat.py         # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚ ÑƒĞ¼Ğ½Ğ¾Ğ³Ğ¾ Ñ‡Ğ°Ñ‚Ğ°
    â”‚   â”‚   â”œâ”€â”€ container.py              # DI ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â”œâ”€â”€ core                        # Ğ¯Ğ´Ñ€Ğ¾ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py             # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py            # Ğ›Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py              # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Redis
    â”‚   â”‚   â”‚   â”œâ”€â”€ security.py           # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ¸ ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
    â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py             # Ğ—Ğ°Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¾Ğ¿ĞµÑ€Ğ°Ñ†Ğ¸Ğ¹
    â”‚   â”‚   â”‚   â”œâ”€â”€ tokens.py             # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸
    â”‚   â”‚   â”‚   â””â”€â”€ vault.py              # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ÑĞµĞºÑ€ĞµÑ‚Ğ½Ñ‹Ğ¼ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼
    â”‚   â”‚   â”œâ”€â”€ dependencies               # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ FastAPI
    â”‚   â”‚   â”‚   â”œâ”€â”€ agent_params.py       # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py               # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py          # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limit.py         # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ ĞºĞ¾Ğ»Ğ¸Ñ‡ĞµÑÑ‚Ğ²Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ security.py           # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ user.py               # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
    â”‚   â”‚   â”‚   â””â”€â”€ validation.py         # ĞĞ±Ñ‰Ğ°Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    â”‚   â”‚   â”œâ”€â”€ embeddings                 # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ clients               # ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ client.py         # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ¸ĞµĞ½Ñ‚ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ gemini_client.py  # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Gemini
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ openai_client.py  # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ OpenAI
    â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py            # Ğ¤Ğ°Ğ±Ñ€Ğ¸ĞºĞ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py            # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ service.py            # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ similarity.py         # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸
    â”‚   â”‚   â”‚   â””â”€â”€ vector_store.py       # Ğ¥Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ¾Ğ²
    â”‚   â”‚   â”œâ”€â”€ inference                         # ĞœĞ¾Ğ´ÑƒĞ»ÑŒ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»ĞµĞ¹
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference_repository.py       # Ğ ĞµĞ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ¹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ inference_service.py  # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
    â”‚   â”‚   â”‚   â””â”€â”€ workers               # Ğ Ğ°Ğ±Ğ¾Ñ‡Ğ¸Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
    â”‚   â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ñ€ĞºĞµÑ€
    â”‚   â”‚   â”‚       â”œâ”€â”€ inference_worker.py       # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ñ€ĞºĞµÑ€
    â”‚   â”‚   â”‚       â”œâ”€â”€ job_handler       # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ base.py       # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ°
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ llm_handler.py        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº LLM 
    â”‚   â”‚   â”‚       â”‚   â”œâ”€â”€ react_handler.py      # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº ReAct Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    â”‚   â”‚   â”‚       â”‚   â””â”€â”€ smart_orchestration_handler.py        # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸Ğº Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
    â”‚   â”‚   â”‚       â””â”€â”€ worker_main.py   # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°
    â”‚   â”‚   â”œâ”€â”€ infra                    # Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py           # Ğ Ğ°Ğ·Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ db                   # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ‘Ğ”
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models           # ĞœĞ¾Ğ´ĞµĞ»Ğ¸ Ğ‘Ğ”
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py      # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ
    â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ models.py    # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ ĞºĞ¾Ğ»Ğ»ĞµĞºÑ†Ğ¸Ğ¹
    â”‚   â”‚   â”‚   â”‚   â”‚   â””â”€â”€ user_model.py  # ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ pg.py              # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ PostgreSQL
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qdrant.py          # ĞŸĞ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Qdrant
    â”‚   â”‚   â”‚   â””â”€â”€ pdf_loader.py          # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° PDF
    â”‚   â”‚   â”œâ”€â”€ llm                         # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ adapters               # ĞĞ´Ğ°Ğ¿Ñ‚ĞµÑ€Ñ‹ Ğ´Ğ»Ñ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… LLM
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ client.py          # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ¸ĞµĞ½Ñ‚
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ geminiAdapter.py   # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Gemini
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ollamaAdapter.py   # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ollama
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py   # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ OpenAI
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qwen3vlAdapter.py  # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Qwen3 4B VL Instruct
    â”‚   â”‚   â”‚   â”œâ”€â”€ config.py            # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py           # LLM Factory
    â”‚   â”‚   â”‚   â”œâ”€â”€ filter.py            # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€ LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py        # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ‚Ğ¾Ñ€ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py            # LLM Runner
    â”‚   â”‚   â”‚   â”œâ”€â”€ sanitizer.py         # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸
    â”‚   â”‚   â”‚   â””â”€â”€ schemas.py           # Ğ¡Ñ…ĞµĞ¼Ñ‹ LLM (Ğ²Ğ²Ğ¾Ğ´/Ğ²Ñ‹Ğ²Ğ¾Ğ´/gen ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³)
    â”‚   â”‚   â”œâ”€â”€ main.py                     # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° FastAPI Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â”œâ”€â”€ middlewares                # Middleware FastAPI
    â”‚   â”‚   â”‚   â”œâ”€â”€ body.py                # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚ĞµĞ»Ğ° Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    â”‚   â”‚   â”‚   â”œâ”€â”€ observability.py       # ĞœĞµÑ‚Ñ€Ğ¸ĞºĞ¸ Ğ¸ Ğ½Ğ°Ğ±Ğ»ÑĞ´Ğ°ĞµĞ¼Ğ¾ÑÑ‚ÑŒ
    â”‚   â”‚   â”‚   â”œâ”€â”€ prometheus.py          # Ğ­ĞºÑĞ¿Ğ¾Ñ€Ñ‚ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Ğ² Prometheus
    â”‚   â”‚   â”‚   â”œâ”€â”€ timings.py             # Ğ—Ğ°Ğ¼ĞµÑ€Ñ‹ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    â”‚   â”‚   â”‚   â””â”€â”€ tokens.py              # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ² Ğ² middleware
    â”‚   â”‚   â”œâ”€â”€ models                     # ĞœĞ¾Ğ´ĞµĞ»Ğ¸
    â”‚   â”‚   â”‚   â””â”€â”€ user.py                # ĞœĞ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
    â”‚   â”‚   â”œâ”€â”€ schemas                    # Pydantic ÑÑ…ĞµĞ¼Ñ‹
    â”‚   â”‚   â”‚   â”œâ”€â”€ agent.py               # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ / Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py                # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ±Ğ°Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    â”‚   â”‚   â”‚   â””â”€â”€ inference.py           # Ğ¡Ñ…ĞµĞ¼Ñ‹ inference
    â”‚   â”‚   â”œâ”€â”€ services                   # Ğ¡ĞµÑ€Ğ²Ğ¸ÑÑ‹ Ğ±Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py        # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â”‚   â”œâ”€â”€ chat_service.py        # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ñ‡Ğ°Ñ‚Ğ°
    â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py           # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ¸ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
    â”‚   â”‚   â”‚   â”œâ”€â”€ orchestration          # ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ LLM Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ classifier.py      # ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ‚Ğ¾Ñ€ one-shot Ğ¸Ğ»Ğ¸ complex Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ orchestrator.py    # ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€ Ğ¼ĞµĞ¶Ğ´Ñƒ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ñ‹Ğ¼ LLM
    â”‚   â”‚   â”‚   â”œâ”€â”€ prompts                # ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚Ñ‹ Ğ´Ğ»Ñ LLM
    â”‚   â”‚   â”‚   â”‚   â””â”€â”€ classifier_prompt.py  # ĞŸÑ€Ğ¾Ğ¼Ğ¿Ñ‚ ĞºĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚   â”‚   â””â”€â”€ rag_service.py         # Retrieval-Augmented Generation ÑĞµÑ€Ğ²Ğ¸Ñ
    â”‚   â”‚   â”œâ”€â”€ startup.py                 # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
    â”‚   â”‚   â””â”€â”€ validators                 # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€Ñ‹
    â”‚   â”‚       â”œâ”€â”€ agent.py               # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
    â”‚   â”‚       â”œâ”€â”€ generation.py          # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğ¹ generation ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ğ¸
    â”‚   â”‚       â”œâ”€â”€ provider.py            # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ²
    â”‚   â”‚       â””â”€â”€ timeout.py             # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ°
    â”‚   â”œâ”€â”€ Dockerfile                      # Dockerfile Ğ´Ğ»Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ° API
    â”‚   â”œâ”€â”€ prometheus.yaml                 # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ° Prometheus
    â”‚   â”œâ”€â”€ reflection.md                   # Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ/Ñ€ĞµÑ„Ğ»ĞµĞºÑĞ¸Ñ Ğ¿Ğ¾ ÑĞµÑ€Ğ²Ğ¸ÑÑƒ
    â”‚   â””â”€â”€ requirements.txt                # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Python Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
    â””â”€â”€ qwen                                # ĞÑ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ Qwen
        â”œâ”€â”€ Dockerfile.qwen                 # Dockerfile Ğ´Ğ»Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ° Qwen
        â”œâ”€â”€ inference_service.py            # Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
        â””â”€â”€ main.py                         # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ñ„Ğ°Ğ¹Ğ» ÑĞµÑ€Ğ²Ğ¸ÑĞ° Qwen
```
â¸»

### ğŸ³ Docker: ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº
ĞŸĞ¾Ğ´ÑĞºĞ°Ğ·ĞºĞ°: Ğ•ÑĞ»Ğ¸ Ğ’Ñ‹ ÑÑ‡Ğ°ÑÑ‚Ğ»Ğ¸Ğ²Ñ‹Ğ¹ Ğ¾Ğ±Ğ»Ğ°Ğ´Ğ°Ñ‚ĞµĞ»ÑŒ Apple Silicon, Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ğ¹Ñ‚Ğµ Ollama/Qwen/Ğ»ÑĞ±ÑƒÑ open source Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ğ¾, Ğ½Ğµ Ñ‡ĞµÑ€ĞµĞ· Docker

1.	Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²:
```bash
docker-compose up --build
```
2.	API Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¿Ğ¾ Ğ°Ğ´Ñ€ĞµÑÑƒ:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Vault KV:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  QWEN3_VL_BASE_URL="http://host.docker.internal:8000" \
  ALLOWED_PROVIDERS='["openai","gemini","ollama","qwen3vl"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```
5. Ğ—Ğ°Ğ¿ÑƒÑĞº Qwen3 Inference API:
- Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°Ñ Apple Silicon:
```bash
uvicorn services.qwen.main:app --reload
```
- Ğ•ÑĞ»Ğ¸ Ñƒ Ğ²Ğ°ÑˆĞµĞ³Ğ¾ Ğ³Ñ€Ğ°Ñ„Ğ¸Ñ‡ĞµÑĞºĞ¾Ğ³Ğ¾ ÑĞ´Ñ€Ğ° ĞµÑÑ‚ÑŒ Ğ´Ñ€Ğ°Ğ¹Ğ²ĞµÑ€Ğ° Ğ² Docker - Ñ€Ğ°ÑĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€ÑƒĞ¹Ñ‚Ğµ docker compose qwen Ğ±Ğ»Ğ¾Ğº Ğ¸ ÑĞ¼ĞµĞ½Ğ¸Ñ‚Ğµ Vault secret QWEN3_VL_BASE_URL Ğ¸ model path Ğ½Ğ° "/models/qwen3v1".
â¸»

### ğŸ”‘ ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```
â¸»

### ğŸ’¡ Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹

#### /auth
- POST /auth/login â€” Ğ»Ğ¾Ğ³Ğ¸Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT
- POST /auth/register â€” Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ°) Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT

#### /chat
- POST /chat/ â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM
- POST /chat/rag â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG
- POST /chat/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- POST /chat/rag/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id

#### /agents
- POST /agents/run â€” Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ Ñ†ĞµĞ»ÑŒÑ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- GET /agents/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑˆĞ°Ğ³Ğ¾Ğ²
- GET /agents/tools â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°

#### /embeddings
- POST /embeddings/search â€” ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

#### /ingestion
- POST /ingestion/ingest â€” Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° PDF-Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ‘Ğ” Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸

#### /search
- GET /search/ â€” Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹

#### /inference
- POST /inference/ â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

â¸»

### âš™ï¸ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ñ€ĞºĞµÑ€ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°

#### ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:
ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğº LLM. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ LLM Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ â€” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¶Ğµ Ğ¿Ğ¾ job_id.

#### Workflow
1.	Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ: Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² /chat/async Ğ¸Ğ»Ğ¸ /chat/rag/async
2.	ĞÑ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹: Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ°ÑÑ‚ Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ½Ğ° Redis Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ² Ğ¸ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ½Ğ° LLM
3.	Ğ’Ğ¾Ñ€ĞºĞµÑ€Ñ‹: Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ÑÑ‚ÑÑ ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹/ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:

- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº LLM (OpenAI/Gemini)
- ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒÑÑ‚, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒÑÑ‚ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚/Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² Redis

4.	Heartbeat: Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ heartbeat
5.	ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²: GET /inference/{job_id} Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:

- status: pending, completed, error
- result (ĞµÑĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾)
- error message (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)

#### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°:
```bash
python -m app.inference.workers.worker_main
```
- ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ¾Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
- Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹
- ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° rate-limiting Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ¸ LLM

#### Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹
- POST /chat/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ LLM
- POST /chat/rag/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ RAG
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

â¸»

#### ğŸ“š Ğ ĞµÑÑƒÑ€ÑÑ‹
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ OpenAI API](https://platform.openai.com/docs/api-reference/introduction)
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Gemini API](https://ai.google.dev/gemini-api/docs?hl=ru)
- [HuggingFace](https://huggingface.co/)
- [Ollama](https://ollama.com)