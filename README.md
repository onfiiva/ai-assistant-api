# AI Assistant API

[English](#english) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](#Ñ€ÑƒÑÑĞºĞ¸Ğ¹)

- [ğŸ³ Installation](#-docker-setup--running)
- [ğŸ³ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°](#-docker-ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°-Ğ¸-Ğ·Ğ°Ğ¿ÑƒÑĞº)

â¸»

## English

The ai-assistant-api project allows interaction with LLMs (Large Language Models) via API.
Supported models: OpenAI and Gemini.

With this project, you can:
- Send requests to LLMs (sync, async and via agent)
- Use RAG (retrieval-augmented generation)
- Experiment with generation parameters (temperature, top_p, max_tokens, etc.)
- Track job status via async inference API
- Control request timeouts
- Save responses in JSON format for analysis and testing
- Switch between multiple LLM providers in the same request
- Filter system/forbidden commands and sanitize user input
- Track and log malicious requests
- Apply rate limiting per user/admin
- Embed documents, store them in a vector database (Qdrant), and perform semantic search
- Work with multi-language content and large documents by chunking
- Swagger UI with JWT authorization support
- Use async inference workers with job queue and heartbeat monitoring

â¸»

### ğŸ“ Project Structure
```
ai-assistant-api/
â”œâ”€â”€ alembic/                    # Database migrations for PostgreSQL
â”‚   â”œâ”€â”€ env.py                  # Alembic environment configuration
â”‚   â”œâ”€â”€ README                  # Notes and description for migrations
â”‚   â”œâ”€â”€ script.py.mako          # Template for migration scripts
â”‚   â””â”€â”€ versions/               # Folder containing migration files
â”‚       â””â”€â”€ <migration_files>   # Python migration scripts
â”œâ”€â”€ alembic.ini                  # Alembic configuration
â”œâ”€â”€ app/                        # Main application package
â”‚   â”œâ”€â”€ api/                    # FastAPI endpoint definitions
â”‚   â”‚   â”œâ”€â”€ agents.py           # Endpoints for agent actions, status, and tools
â”‚   â”‚   â”œâ”€â”€ auth.py             # Endpoints for login/register users
â”‚   â”‚   â”œâ”€â”€ chat.py             # Synchronous chat endpoints (/chat/, /chat/rag)
â”‚   â”‚   â”œâ”€â”€ chat_async.py       # Async chat endpoints (/chat/async, /chat/rag/async)
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Endpoints for embedding searches
â”‚   â”‚   â”œâ”€â”€ ingestion.py        # Endpoint to ingest PDFs into vector DB
â”‚   â”‚   â”œâ”€â”€ search.py           # GET endpoint to search stored embeddings
â”‚   â”‚   â””â”€â”€ inference.py        # Endpoints to manage async inference jobs
â”‚   â”œâ”€â”€ agents/                 # Agent logic and memory management
â”‚   â”‚   â”œâ”€â”€ actions.py          # Agent action implementations
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic schemas for agent input/output
â”‚   â”‚   â”œâ”€â”€ memory/             # Agent memory backends
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py         # Base memory class
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py    # Memory implementation in RAM
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py        # Redis synchronous memory
â”‚   â”‚   â”‚   â””â”€â”€ redis_async.py  # Redis async memory
â”‚   â”‚   â””â”€â”€ tools/              # Agent tool implementations
â”‚   â”‚       â”œâ”€â”€ actions/        # Tool actions
â”‚   â”‚       â”‚   â””â”€â”€ execute.py  # Universal tool executor
â”‚   â”‚       â”œâ”€â”€ base.py         # Base tool class
â”‚   â”‚       â”œâ”€â”€ registry.py     # Tool registry
â”‚   â”‚       â”œâ”€â”€ external_api.py # External API call tool
â”‚   â”‚       â”œâ”€â”€ summary.py      # Summary tool
â”‚   â”‚       â”œâ”€â”€ validation.py   # Tool validation schema
â”‚   â”‚       â”œâ”€â”€ vector_search.py        # Vector search tool
â”‚   â”‚       â”œâ”€â”€ vector_search_async.py  # Vector search async tool
â”‚   â”‚       â””â”€â”€ search.py       # Search tool
â”‚   â”œâ”€â”€ container.py            # Dependency injection container setup
â”‚   â”œâ”€â”€ core/                   # Core application configurations and utilities
â”‚   â”‚   â”œâ”€â”€ config.py           # Application settings and environment variables
â”‚   â”‚   â”œâ”€â”€ logging.py          # Logging configuration
â”‚   â”‚   â”œâ”€â”€ redis.py            # Redis client configuration (rate limits, jobs)
â”‚   â”‚   â”œâ”€â”€ security.py         # Security helpers (password hashing, token checks)
â”‚   â”‚   â”œâ”€â”€ timing.py           # Request timing utilities
â”‚   â”‚   â”œâ”€â”€ tokens.py           # JWT token utilities
â”‚   â”‚   â””â”€â”€ vault.py            # Vault client helper
â”‚   â”œâ”€â”€ dependencies/           # FastAPI dependencies for endpoints
â”‚   â”‚   â”œâ”€â”€ agent_params.py     # Validates agent parameters
â”‚   â”‚   â”œâ”€â”€ auth.py             # Current user retrieval
â”‚   â”‚   â”œâ”€â”€ inference.py        # Provides InferenceService instance
â”‚   â”‚   â”œâ”€â”€ rate_limit.py       # Rate limiting per user/admin
â”‚   â”‚   â”œâ”€â”€ security.py         # Security middleware dependency
â”‚   â”‚   â”œâ”€â”€ user.py             # Current user context
â”‚   â”‚   â””â”€â”€ validation.py       # Input validation for chat requests
â”‚   â”œâ”€â”€ embeddings/             # Embeddings management
â”‚   â”‚   â”œâ”€â”€ clients/            # Provider-specific clients (OpenAI/Gemini)
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_client.py
â”‚   â”‚   â”‚   â””â”€â”€ gemini_client.py
â”‚   â”‚   â”œâ”€â”€ factory.py          # Embeddings service factory
â”‚   â”‚   â”œâ”€â”€ service.py          # Main embeddings service
â”‚   â”‚   â”œâ”€â”€ similarity.py       # Vector similarity calculation
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # Vector DB client (Qdrant)
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic schemas for embeddings
â”‚   â”œâ”€â”€ inference/              # Async inference logic
â”‚   â”‚   â”œâ”€â”€ inference_service.py    # Job creation and status management
â”‚   â”‚   â”œâ”€â”€ inference_repository.py # Redis storage for jobs
â”‚   â”‚   â””â”€â”€ workers/            # Background worker scripts
â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py
â”‚   â”‚       â”œâ”€â”€ inference_worker.py
â”‚   â”‚       â””â”€â”€ worker_main.py  # Entrypoint to run workers
â”‚   â”œâ”€â”€ infra/                  # Infrastructure utilities
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Document chunking logic
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # PDF parsing
â”‚   â”‚   â””â”€â”€ db/                 # Database interactions
â”‚   â”‚       â”œâ”€â”€ models/         # SQLAlchemy models
â”‚   â”‚       â”‚   â”œâ”€â”€ base.py
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py
â”‚   â”‚       â”‚   â””â”€â”€ user_model.py
â”‚   â”‚       â”œâ”€â”€ pg.py           # PostgreSQL client
â”‚   â”‚       â””â”€â”€ qdrant.py       # Qdrant client
â”‚   â”œâ”€â”€ llm/                     # LLM adapters and utilities
â”‚   â”‚   â”œâ”€â”€ adapters/           # LLM provider adapters
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py
â”‚   â”‚   â”‚   â””â”€â”€ geminiAdapter.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ factory.py
â”‚   â”‚   â”œâ”€â”€ filter.py           # Filters for forbidden commands
â”‚   â”‚   â”œâ”€â”€ normalizer.py       # Normalize model outputs
â”‚   â”‚   â”œâ”€â”€ runner.py           # Run LLM requests
â”‚   â”‚   â”œâ”€â”€ sanitizer.py        # User input sanitization
â”‚   â”‚   â””â”€â”€ schemas.py          # Request/response schemas
â”‚   â”œâ”€â”€ main.py                 # FastAPI entrypoint
â”‚   â”œâ”€â”€ middlewares/            # Custom middlewares
â”‚   â”‚   â”œâ”€â”€ body.py
â”‚   â”‚   â”œâ”€â”€ observability.py
â”‚   â”‚   â”œâ”€â”€ prometheus.py
â”‚   â”‚   â”œâ”€â”€ timings.py
â”‚   â”‚   â””â”€â”€ tokens.py
â”‚   â”œâ”€â”€ models/                 # Core data models
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ schemas/                # Pydantic schemas for API input/output
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â”œâ”€â”€ services/               # Application services
â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”œâ”€â”€ chat_service.py
â”‚   â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â””â”€â”€ worker_main.py
â”‚   â””â”€â”€ validators/             # Input validators
â”‚       â”œâ”€â”€ agent.py
â”‚       â”œâ”€â”€ generation.py
â”‚       â”œâ”€â”€ provider.py
â”‚       â””â”€â”€ timeout.py
â”œâ”€â”€ docker-compose.yaml          # Docker Compose configuration
â”œâ”€â”€ Dockerfile                   # Dockerfile for building the service
â”œâ”€â”€ gemini/                      # Scripts to test Gemini API
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ openai/                      # Scripts to test OpenAI API
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ json_requests/               # Stored JSON requests/responses for testing
â”œâ”€â”€ prometheus.yaml              # Prometheus configuration
â”œâ”€â”€ README.md                    # Project README
â”œâ”€â”€ reflection.md                # Notes and reflections
â””â”€â”€ requirements.txt             # Python dependencies
```

â¸»

### ğŸ³ Docker Setup & Running
1.	Build and run containers:
```bash
docker-compose up --build
```
2.	API available at:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	Vault KV setup:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  ALLOWED_PROVIDERS='["openai","gemini"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```

â¸»

### ğŸ”‘ Environment Variables (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```

â¸»

### ğŸ’¡ Endpoints

/auth
- POST /auth/login â€” login user and return JWT token
- POST /auth/register â€” register a new user (admin only) and return JWT token

/chat
- POST /chat/ â€” sync LLM call
- POST /chat/rag â€” sync RAG call
- POST /chat/async â€” async LLM call, returns job_id
- POST /chat/rag/async â€” async RAG call, returns job_id

/agents
- POST /agents/run â€” run an agent with a goal, returns job_id
- GET /agents/{job_id} â€” get agent job status and step history
- GET /agents/tools â€” list available tools for the agent

/embeddings
- POST /embeddings/search â€” semantic search, returns top-k results

/ingestion
- POST /ingestion/ingest â€” ingest PDF documents into vector DB with embeddings

/search
- GET /search/ â€” search pre-ingested embeddings, returns top-k matches

/inference
- POST /inference/ â€” create async inference job
- GET /inference/{job_id} â€” get status and result/error of async job

â¸»

### âš™ï¸ Async Inference Worker

#### Purpose
Handles asynchronous execution of LLM requests. Users do not need to wait for LLM to finish in real-time â€” they can fetch results later using a job_id.

#### Workflow
1.	Job creation: user sends a request to /chat/async or /chat/rag/async
2.	Job queue: jobs enter a Redis-backed queue respecting rate limits and LLM load
3.	Workers: run as separate processes/containers and process jobs:
- Send request to LLM (OpenAI/Gemini)
- Normalize, filter, and log responses
- Save result/error back to Redis
4.	Heartbeat: workers send periodic heartbeat signals
5.	Fetching results: GET /inference/{job_id} returns:
- status: pending, completed, error
- result (if ready)
- error message (if any)

#### Usage
- Run a worker:
```bash
python -m app.inference.workers.worker_main
```
- Multiple workers can run simultaneously
- Load is balanced via job queue
- Works with rate-limiting to prevent overloading LLM

#### Related Endpoints
- POST /chat/async â€” create async LLM job
- POST /chat/rag/async â€” create async RAG job
- GET /inference/{job_id} â€” fetch job result/status

â¸»

### ğŸ“š Resources
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference/introduction)
- [Gemini API Documentation](https://ai.google.dev/gemini-api/docs?hl=en)


## Ğ ÑƒÑÑĞºĞ¸Ğ¹

ĞŸÑ€Ğ¾ĞµĞºÑ‚ ai-assistant-api Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ LLM (Large Language Models â€” Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸) Ñ‡ĞµÑ€ĞµĞ· API.
ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸: OpenAI Ğ¸ Gemini.

Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ:
- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº LLM (ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾, Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ³ĞµĞ½Ñ‚Ğ°)
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ RAG (retrieval-augmented generation â€” Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ°)
- Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (temperature, top_p, max_tokens Ğ¸ Ğ´Ñ€.)
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ API Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ LLM-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ
- Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ/Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ Ğ¾Ñ‡Ğ¸Ñ‰Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ²Ğ²Ğ¾Ğ´
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ/Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
- Ğ’ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¸Ñ… Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ‘Ğ” (Qdrant) Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°Ñ Ğ¸Ñ… Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Swagger UI Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· JWT
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ñ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ heartbeat

â¸»

### ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
```
ai-assistant-api/
â”œâ”€â”€ alembic/                    # ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… PostgreSQL
â”‚   â”œâ”€â”€ env.py                  # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ Alembic
â”‚   â”œâ”€â”€ README                  # Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ¸ Ğ¸ Ğ¾Ğ¿Ğ¸ÑĞ°Ğ½Ğ¸Ğµ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
â”‚   â”œâ”€â”€ script.py.mako          # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ° Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸
â”‚   â””â”€â”€ versions/               # ĞŸĞ°Ğ¿ĞºĞ° Ñ Ñ„Ğ°Ğ¹Ğ»Ğ°Ğ¼Ğ¸ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
â”‚       â””â”€â”€ <migration_files>   # Python-ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
â”œâ”€â”€ alembic.ini                  # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Alembic
â”œâ”€â”€ app/                        # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ Ğ¿Ğ°ĞºĞµÑ‚ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”œâ”€â”€ api/                    # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ñ FastAPI ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ agents.py           # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°, ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ auth.py             # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ»Ğ¾Ğ³Ğ¸Ğ½Ğ°/Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ĞµĞ¹
â”‚   â”‚   â”œâ”€â”€ chat.py             # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ñ‡Ğ°Ñ‚-ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ (/chat/, /chat/rag)
â”‚   â”‚   â”œâ”€â”€ chat_async.py       # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ñ‡Ğ°Ñ‚-ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ (/chat/async, /chat/rag/async)
â”‚   â”‚   â”œâ”€â”€ embeddings.py       # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼
â”‚   â”‚   â”œâ”€â”€ ingestion.py        # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚ Ğ´Ğ»Ñ Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ PDF Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ‘Ğ”
â”‚   â”‚   â”œâ”€â”€ search.py           # GET-ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚ Ğ´Ğ»Ñ Ğ¿Ğ¾Ğ¸ÑĞºĞ° Ğ¿Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼
â”‚   â”‚   â””â”€â”€ inference.py        # Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ñ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¼Ğ¸ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸ÑĞ¼Ğ¸ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
â”‚   â”œâ”€â”€ agents/                 # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒÑ
â”‚   â”‚   â”œâ”€â”€ actions.py          # Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”œâ”€â”€ schemas.py          # Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ²Ğ²Ğ¾Ğ´Ğ°/Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ° Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”œâ”€â”€ memory/             # Ğ‘ÑĞºĞµĞ½Ğ´Ñ‹ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py         # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py    # ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ² RAM
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py        # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Redis
â”‚   â”‚   â”‚   â””â”€â”€ redis_async.py  # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ Redis
â”‚   â”‚   â””â”€â”€ tools/              # Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚       â”œâ”€â”€ actions/        # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚       â”‚   â””â”€â”€ execute.py  # Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚       â”œâ”€â”€ base.py         # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°
â”‚   â”‚       â”œâ”€â”€ registry.py     # Ğ ĞµĞµÑÑ‚Ñ€ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚       â”œâ”€â”€ external_api.py # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ²Ñ‹Ğ·Ğ¾Ğ²Ğ° Ğ²Ğ½ĞµÑˆĞ½ĞµĞ¹ API
â”‚   â”‚       â”œâ”€â”€ summary.py      # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ summary
â”‚   â”‚       â”œâ”€â”€ validation.py   # Ğ¡Ñ…ĞµĞ¼Ğ° Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ğ¸ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚       â”œâ”€â”€ vector_search.py        # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
â”‚   â”‚       â”œâ”€â”€ vector_search_async.py  # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
â”‚   â”‚       â””â”€â”€ search.py       # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ¿Ğ¾Ğ¸ÑĞºĞ°
â”‚   â”œâ”€â”€ container.py            # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° DI-ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ°
â”‚   â”œâ”€â”€ core/                   # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¸ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ config.py           # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ Ğ¸ Ğ¿ĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ logging.py          # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ redis.py            # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Redis (Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹, Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ)
â”‚   â”‚   â”œâ”€â”€ security.py         # Ğ¡ĞµĞºÑŒÑÑ€Ğ¸Ñ‚Ğ¸-Ñ…ĞµĞ»Ğ¿ĞµÑ€Ñ‹ (Ñ…ĞµÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°Ñ€Ğ¾Ğ»ĞµĞ¹, Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ñ‚Ğ¾ĞºĞµĞ½Ğ¾Ğ²)
â”‚   â”‚   â”œâ”€â”€ timing.py           # Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ·Ğ°Ğ¼ĞµÑ€Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ tokens.py           # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ JWT Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸
â”‚   â”‚   â””â”€â”€ vault.py            # Ğ¥ĞµĞ»Ğ¿ĞµÑ€ Ğ´Ğ»Ñ Vault
â”‚   â”œâ”€â”€ dependencies/           # FastAPI Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸ Ğ´Ğ»Ñ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ agent_params.py     # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ² Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”œâ”€â”€ auth.py             # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
â”‚   â”‚   â”œâ”€â”€ inference.py        # ĞŸÑ€ĞµĞ´Ğ¾ÑÑ‚Ğ°Ğ²Ğ»ÑĞµÑ‚ ÑĞºĞ·ĞµĞ¼Ğ¿Ğ»ÑÑ€ InferenceService
â”‚   â”‚   â”œâ”€â”€ rate_limit.py       # Ğ›Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ/Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
â”‚   â”‚   â”œâ”€â”€ security.py         # Ğ—Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚ÑŒ Ğ´Ğ»Ñ ÑĞµĞºÑŒÑÑ€Ğ¸Ñ‚Ğ¸ middleware
â”‚   â”‚   â”œâ”€â”€ user.py             # ĞšĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚ Ñ‚ĞµĞºÑƒÑ‰ĞµĞ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
â”‚   â”‚   â””â”€â”€ validation.py       # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ñ‡Ğ°Ñ‚Ğ°
â”‚   â”œâ”€â”€ embeddings/             # Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸
â”‚   â”‚   â”œâ”€â”€ clients/            # ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ´Ğ»Ñ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² (OpenAI/Gemini)
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openai_client.py
â”‚   â”‚   â”‚   â””â”€â”€ gemini_client.py
â”‚   â”‚   â”œâ”€â”€ factory.py          # Ğ¤Ğ°Ğ±Ñ€Ğ¸ĞºĞ° ÑĞµÑ€Ğ²Ğ¸ÑĞ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ service.py          # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ÑĞµÑ€Ğ²Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ similarity.py       # Ğ’Ñ‹Ñ‡Ğ¸ÑĞ»ĞµĞ½Ğ¸Ğµ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ ÑÑ…Ğ¾Ğ¶ĞµÑÑ‚Ğ¸
â”‚   â”‚   â”œâ”€â”€ vector_store.py     # ĞšĞ»Ğ¸ĞµĞ½Ñ‚ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ‘Ğ” (Qdrant)
â”‚   â”‚   â””â”€â”€ schemas.py          # Pydantic ÑÑ…ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”œâ”€â”€ inference/              # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
â”‚   â”‚   â”œâ”€â”€ inference_service.py    # Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ¾Ğ¼
â”‚   â”‚   â”œâ”€â”€ inference_repository.py # Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ² Redis
â”‚   â”‚   â””â”€â”€ workers/            # Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ Ñ„Ğ¾Ğ½Ğ¾Ğ²Ñ‹Ñ… Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ¾Ğ²
â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py
â”‚   â”‚       â”œâ”€â”€ inference_worker.py
â”‚   â”‚       â””â”€â”€ worker_main.py  # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ¾Ğ²
â”‚   â”œâ”€â”€ infra/                  # Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹
â”‚   â”‚   â”œâ”€â”€ chunker.py          # Ğ Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
â”‚   â”‚   â”œâ”€â”€ pdf_loader.py       # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ PDF
â”‚   â”‚   â””â”€â”€ db/                 # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ±Ğ°Ğ·Ğ¾Ğ¹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚       â”œâ”€â”€ models/         # SQLAlchemy Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚   â”‚       â”‚   â”œâ”€â”€ base.py
â”‚   â”‚       â”‚   â”œâ”€â”€ models.py
â”‚   â”‚       â”‚   â””â”€â”€ user_model.py
â”‚   â”‚       â”œâ”€â”€ pg.py           # PostgreSQL ĞºĞ»Ğ¸ĞµĞ½Ñ‚
â”‚   â”‚       â””â”€â”€ qdrant.py       # Qdrant ĞºĞ»Ğ¸ĞµĞ½Ñ‚
â”‚   â”œâ”€â”€ llm/                     # ĞĞ´Ğ°Ğ¿Ñ‚ĞµÑ€Ñ‹ LLM Ğ¸ ÑƒÑ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹
â”‚   â”‚   â”œâ”€â”€ adapters/           # ĞĞ´Ğ°Ğ¿Ñ‚ĞµÑ€Ñ‹ Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ client.py
â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py
â”‚   â”‚   â”‚   â””â”€â”€ geminiAdapter.py
â”‚   â”‚   â”œâ”€â”€ config.py
â”‚   â”‚   â”œâ”€â”€ factory.py
â”‚   â”‚   â”œâ”€â”€ filter.py           # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ñ‹ Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½Ğ½Ñ‹Ñ… ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´
â”‚   â”‚   â”œâ”€â”€ normalizer.py       # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ² Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸
â”‚   â”‚   â”œâ”€â”€ runner.py           # Ğ’Ñ‹Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğº LLM
â”‚   â”‚   â”œâ”€â”€ sanitizer.py        # ĞÑ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¾Ğ³Ğ¾ Ğ²Ğ²Ğ¾Ğ´Ğ°
â”‚   â”‚   â””â”€â”€ schemas.py          # Ğ¡Ñ…ĞµĞ¼Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²/Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
â”‚   â”œâ”€â”€ main.py                 # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° FastAPI
â”‚   â”œâ”€â”€ middlewares/            # ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğµ middleware
â”‚   â”‚   â”œâ”€â”€ body.py
â”‚   â”‚   â”œâ”€â”€ observability.py
â”‚   â”‚   â”œâ”€â”€ prometheus.py
â”‚   â”‚   â”œâ”€â”€ timings.py
â”‚   â”‚   â””â”€â”€ tokens.py
â”‚   â”œâ”€â”€ models/                 # ĞÑĞ½Ğ¾Ğ²Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â””â”€â”€ user.py
â”‚   â”œâ”€â”€ schemas/                # Pydantic ÑÑ…ĞµĞ¼Ñ‹ API
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ auth.py
â”‚   â”‚   â”œâ”€â”€ chat.py
â”‚   â”‚   â””â”€â”€ inference.py
â”‚   â”œâ”€â”€ services/               # Ğ¡ĞµÑ€Ğ²Ğ¸ÑÑ‹ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ auth_service.py
â”‚   â”‚   â”œâ”€â”€ chat_service.py
â”‚   â”‚   â”œâ”€â”€ ingestion.py
â”‚   â”‚   â”œâ”€â”€ rag_service.py
â”‚   â”‚   â””â”€â”€ worker_main.py
â”‚   â””â”€â”€ validators/             # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚       â”œâ”€â”€ agent.py
â”‚       â”œâ”€â”€ generation.py
â”‚       â”œâ”€â”€ provider.py
â”‚       â””â”€â”€ timeout.py
â”œâ”€â”€ docker-compose.yaml          # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Docker Compose
â”œâ”€â”€ Dockerfile                   # Dockerfile Ğ´Ğ»Ñ ÑĞ±Ğ¾Ñ€ĞºĞ¸ ÑĞµÑ€Ğ²Ğ¸ÑĞ°
â”œâ”€â”€ gemini/                      # Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ Gemini API
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ openai/                      # Ğ¡ĞºÑ€Ğ¸Ğ¿Ñ‚Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ OpenAI API
â”‚   â””â”€â”€ main.py
â”œâ”€â”€ json_requests/               # Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½Ñ‘Ğ½Ğ½Ñ‹Ğµ JSON-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹/Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ´Ğ»Ñ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
â”œâ”€â”€ prometheus.yaml              # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Prometheus
â”œâ”€â”€ README.md                    # README Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
â”œâ”€â”€ reflection.md                # Ğ—Ğ°Ğ¼ĞµÑ‚ĞºĞ¸ Ğ¸ Ñ€Ğ°Ğ·Ğ¼Ñ‹ÑˆĞ»ĞµĞ½Ğ¸Ñ
â””â”€â”€ requirements.txt             # Python-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
```
â¸»

### ğŸ³ Docker: ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº
1.	Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²:
```bash
docker-compose up --build
```
2.	API Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¿Ğ¾ Ğ°Ğ´Ñ€ĞµÑÑƒ:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Vault KV:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  ALLOWED_PROVIDERS='["openai","gemini"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```
â¸»

### ğŸ”‘ ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```
â¸»

### ğŸ’¡ Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹

#### /auth
- POST /auth/login â€” Ğ»Ğ¾Ğ³Ğ¸Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT
- POST /auth/register â€” Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ°) Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT

#### /chat
- POST /chat/ â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM
- POST /chat/rag â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG
- POST /chat/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- POST /chat/rag/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id

#### /agents
- POST /agents/run â€” Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ Ñ†ĞµĞ»ÑŒÑ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- GET /agents/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑˆĞ°Ğ³Ğ¾Ğ²
- GET /agents/tools â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°

#### /embeddings
- POST /embeddings/search â€” ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

#### /ingestion
- POST /ingestion/ingest â€” Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° PDF-Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ‘Ğ” Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸

#### /search
- GET /search/ â€” Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹

#### /inference
- POST /inference/ â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

â¸»

### âš™ï¸ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ñ€ĞºĞµÑ€ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°

#### ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:
ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğº LLM. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ LLM Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ â€” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¶Ğµ Ğ¿Ğ¾ job_id.

#### Workflow
1.	Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ: Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² /chat/async Ğ¸Ğ»Ğ¸ /chat/rag/async
2.	ĞÑ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹: Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ°ÑÑ‚ Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ½Ğ° Redis Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ² Ğ¸ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ½Ğ° LLM
3.	Ğ’Ğ¾Ñ€ĞºĞµÑ€Ñ‹: Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ÑÑ‚ÑÑ ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹/ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:

- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº LLM (OpenAI/Gemini)
- ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒÑÑ‚, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒÑÑ‚ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚/Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² Redis

4.	Heartbeat: Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ heartbeat
5.	ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²: GET /inference/{job_id} Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:

- status: pending, completed, error
- result (ĞµÑĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾)
- error message (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)

#### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°:
```bash
python -m app.inference.workers.worker_main
```
- ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ¾Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
- Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹
- ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° rate-limiting Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ¸ LLM

#### Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹
- POST /chat/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ LLM
- POST /chat/rag/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ RAG
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

â¸»

#### ğŸ“š Ğ ĞµÑÑƒÑ€ÑÑ‹
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ OpenAI API](https://platform.openai.com/docs/api-reference/introduction)
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Gemini API](https://ai.google.dev/gemini-api/docs?hl=ru)