# AI Assistant API

[English](#english) | [Ğ ÑƒÑÑĞºĞ¸Ğ¹](#Ñ€ÑƒÑÑĞºĞ¸Ğ¹)

- [ğŸ³ Installation](#-docker-setup--running)
- [ğŸ³ Ğ£ÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°](#-docker-ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ°-Ğ¸-Ğ·Ğ°Ğ¿ÑƒÑĞº)

â¸»

## English

The ai-assistant-api project allows interaction with LLMs (Large Language Models) via API.
Supported models:
- [OpenAI](https://openai.com)
- [Gemini](https://gemini.google.com)

Local supported models:
[API for Qwen models](https://github.com/onfiiva/qwen3-apis)

- [Ollama](https://ollama.com)
[mistral:7b-instruct-q4_K_M](https://ollama.com/library/mistral:7b-instruct-q4_K_M)
- [Qwen3](https://qwen.ai/)
[Qwen3-4B-VL-Instruct](https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct)
[Qwen3-TTS-12Hz-1.7B-CustomVoice](https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice)


With this project, you can:
- Send requests to LLMs (sync, async and via agent)
- Use RAG (retrieval-augmented generation)
- Experiment with generation parameters (temperature, top_p, max_tokens, etc.)
- Track job status via async inference API
- Control request timeouts
- Save responses in JSON format for analysis and testing
- Switch between multiple LLM providers in the same request
- Filter system/forbidden commands and sanitize user input
- Track and log malicious requests
- Apply rate limiting per user/admin
- Embed documents, store them in a vector database (Qdrant), and perform semantic search
- Work with multi-language content and large documents by chunking
- Swagger UI with JWT authorization support
- Use async inference workers with job queue and heartbeat monitoring
- Simple LoRa
- Send requests to LMStudio
- Send TTS voice generation requests

â¸»

### ğŸ“ Project Structure
```bash
ai-assistant-api/                         # Root directory of the AI assistant project
â”œâ”€â”€ api/                                  # Main backend service (FastAPI)
â”‚   â”œâ”€â”€ alembic/                          # Database migrations (Alembic)
â”‚   â”‚   â”œâ”€â”€ env.py                        # Alembic initialization and DB connection setup
â”‚   â”‚   â”œâ”€â”€ README                        # Migration documentation
â”‚   â”‚   â”œâ”€â”€ script.py.mako                # Migration file generation template
â”‚   â”‚   â””â”€â”€ versions/                     # Migration history
â”‚   â”œâ”€â”€ alembic.ini                       # Alembic configuration (DB URL and settings)
â”‚   â”œâ”€â”€ app/                              # Main application source code
â”‚   â”‚   â”œâ”€â”€ agents/                       # AI agent logic (ReAct, tool-based, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ actions.py                # Definition of possible agent actions
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # Agent configuration (temperature, limits, etc.)
â”‚   â”‚   â”‚   â”œâ”€â”€ memory/                   # Agent memory subsystem
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py               # Base memory interface
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py          # In-memory storage
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis_async.py        # Asynchronous Redis memory
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py              # Synchronous Redis memory
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ summarize.py          # Conversation history summarization
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ vector_memory.py      # Vector-based memory (RAG)
â”‚   â”‚   â”‚   â”œâ”€â”€ react/                    # ReAct agent implementation
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ agent.py              # ReAct loop logic (Thought â†’ Action â†’ Observation)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Pydantic schemas for agents
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ summary.py            # Conversation summarization service
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                  # Agent state management
â”‚   â”‚   â”‚   â””â”€â”€ tools/                    # Tools available to the agent
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py           # Tools package initialization
â”‚   â”‚   â”‚       â”œâ”€â”€ actions/execute.py    # Agent action execution logic
â”‚   â”‚   â”‚       â”œâ”€â”€ base.py               # Base tool class
â”‚   â”‚   â”‚       â”œâ”€â”€ external_api.py       # External API integrations
â”‚   â”‚   â”‚       â”œâ”€â”€ registry.py           # Tool registry
â”‚   â”‚   â”‚       â”œâ”€â”€ search.py             # Search (local / vector)
â”‚   â”‚   â”‚       â”œâ”€â”€ summary.py            # Data summarization tool
â”‚   â”‚   â”‚       â”œâ”€â”€ validation.py         # Tool input validation
â”‚   â”‚   â”‚       â”œâ”€â”€ vector_search_async.py# Asynchronous vector search
â”‚   â”‚   â”‚       â””â”€â”€ vector_search.py      # Synchronous vector search
â”‚   â”‚   â”œâ”€â”€ api/                          # FastAPI HTTP endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py                 # Agent-related API endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                   # Authentication and authorization
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py                   # Synchronous chat endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_async.py             # Asynchronous chat endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py             # Embedding generation endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py              # Generic inference endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py              # Data upload and indexing
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning.py     # Fine-tuning / instruction tuning
â”‚   â”‚   â”‚   â”œâ”€â”€ lmstudio.py               # LM Studio integration
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py                 # Search API endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ smart_chat.py             # Smart orchestrated chat endpoint
â”‚   â”‚   â”‚   â””â”€â”€ tts.py                    # Text-to-Speech endpoint
â”‚   â”‚   â”œâ”€â”€ container.py                  # Dependency Injection container
â”‚   â”‚   â”œâ”€â”€ core/                         # Core infrastructure configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # Global application settings
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py                # Logging configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py                  # Redis configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py               # Security, hashing, encryption
â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py                 # Timing utilities
â”‚   â”‚   â”‚   â”œâ”€â”€ tokens.py                 # Token usage tracking (LLM usage)
â”‚   â”‚   â”‚   â””â”€â”€ vault.py                  # Secret vault integration
â”‚   â”‚   â”œâ”€â”€ dependencies/                 # FastAPI dependency modules
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_params.py           # Agent parameters extraction from request
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                   # Authentication dependency
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py              # Inference dependency
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limit.py             # Request rate limiting
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py               # Security checks
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py                   # Current user extraction
â”‚   â”‚   â”‚   â””â”€â”€ validation.py             # General validation dependency
â”‚   â”‚   â”œâ”€â”€ embeddings/                   # Embedding subsystem
â”‚   â”‚   â”‚   â”œâ”€â”€ clients/                  # External embedding provider clients
â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py                # Embedding client factory
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Embedding data schemas
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Embedding business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ similarity.py             # Similarity calculation
â”‚   â”‚   â”‚   â””â”€â”€ vector_store.py           # Vector storage integration
â”‚   â”‚   â”œâ”€â”€ inference/                    # Asynchronous LLM task processing
â”‚   â”‚   â”‚   â”œâ”€â”€ inference_repository.py   # Task persistence layer
â”‚   â”‚   â”‚   â”œâ”€â”€ inference_service.py      # Inference execution service
â”‚   â”‚   â”‚   â””â”€â”€ workers/                  # Background workers
â”‚   â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py
â”‚   â”‚   â”‚       â”œâ”€â”€ inference_worker.py
â”‚   â”‚   â”‚       â”œâ”€â”€ worker_main.py        # Worker entry point
â”‚   â”‚   â”‚       â””â”€â”€ job_handler/          # Handlers for different job types
â”‚   â”‚   â”œâ”€â”€ infra/                        # Infrastructure layer
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py                # Text chunking utility
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_loader.py             # PDF parsing and loading
â”‚   â”‚   â”‚   â””â”€â”€ db/                       # Database integration
â”‚   â”‚   â”œâ”€â”€ llm/                          # Unified LLM abstraction layer
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/                 # Provider-specific adapters
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base/                 # Base abstractions (generation, embedding, TTS)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ geminiAdapter.py      # Google Gemini adapter
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LMStudioAdapter.py    # LM Studio adapter
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ollamaAdapter.py      # Ollama adapter
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py      # OpenAI adapter
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qwen3TTSAdapter.py    # Qwen TTS adapter
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qwen3vlAdapter.py     # Qwen3-VL (vision-language) adapter
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # LLM configuration
â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py                # LLM factory
â”‚   â”‚   â”‚   â”œâ”€â”€ filter.py                 # Request filtering
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py             # Input normalization
â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py                 # Unified LLM execution runner
â”‚   â”‚   â”‚   â”œâ”€â”€ sanitizer.py              # Prompt sanitization and safety
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py                # LLM request/response schemas
â”‚   â”‚   â”œâ”€â”€ middlewares/                  # FastAPI middleware
â”‚   â”‚   â”œâ”€â”€ models/user.py                # ORM user model
â”‚   â”‚   â”œâ”€â”€ schemas/                      # API Pydantic schemas
â”‚   â”‚   â”œâ”€â”€ services/                     # Application business logic
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py           # Authentication logic
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_service.py           # Chat processing logic
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py              # Data indexing logic
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py            # Retrieval-Augmented Generation logic
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.py            # Text-to-Speech business logic
â”‚   â”‚   â”‚   â””â”€â”€ orchestration/            # LLM and agent orchestration
â”‚   â”‚   â”œâ”€â”€ startup.py                    # Application initialization logic
â”‚   â”‚   â””â”€â”€ validators/                   # Parameter validators
â”‚   â”œâ”€â”€ Dockerfile                        # Docker image definition for API service
â”‚   â”œâ”€â”€ prometheus.yaml                   # Prometheus metrics configuration
â”‚   â”œâ”€â”€ reflection.md                     # Architecture notes and reflections
â”‚   â””â”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ docker-compose.yaml                   # Multi-service orchestration (API, DB, Redis, etc.)
â””â”€â”€ README.md                             # General project documentation
```

â¸»

### ğŸ³ Docker Setup & Running

1.	Build and run containers:
```bash
docker-compose up --build
```
2.	API available at:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	Vault KV setup:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  QWEN3_VL_BASE_URL="http://host.docker.internal:8000" \
  QWEN_TTS_BASE_URL="http://host.docker.internal:8000" \
  TTS_API_URL="http://host.docker.internal:9000" \
  LMSTUDIO_BASE_URL="https://lsstudio.monti215.ru/" \
  LMSTUDIO_API_KEY="sk-lm-JvooJLfY:rhAqs2DhJudo0L2DIh3D" \
  ALLOWED_PROVIDERS='["openai","gemini","ollama","qwen-tts","lmstudio"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```

â¸»

### ğŸ”‘ Environment Variables (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```

â¸»

### ğŸ’¡ Endpoints

#### /auth
- POST /auth/login â€” login user and return JWT token
- POST /auth/register â€” register a new user (admin only) and return JWT token

#### /chat
- POST /chat/ â€” sync LLM call
- POST /chat/rag â€” sync RAG call
- POST /chat/async â€” async LLM call, returns job_id
- POST /chat/rag/async â€” async RAG call, returns job_id

#### /chat/smart
- POST /chat/smart/run - process a single-shot or complex prompt via agent or raw LLM

#### /agents
- POST /agents/run â€” run an agent with a goal, returns job_id
- GET /agents/{job_id} â€” get agent job status and step history
- GET /agents/tools â€” list available tools for the agent

#### /embeddings
- POST /embeddings/search â€” semantic search, returns top-k results

#### /ingestion
- POST /ingestion/ingest â€” ingest PDF documents into vector DB with embeddings

#### /search
- GET /search/ â€” search pre-ingested embeddings, returns top-k matches

#### /inference
- POST /inference/ â€” create async inference job
- GET /inference/{job_id} â€” get status and result/error of async job

#### /tts
- POST / â€” create voice .wav file to download

#### /lmstudio
- GET /models/ â€” search available lmstudio models

â¸»

### âš™ï¸ Async Inference Worker

#### Purpose
Handles asynchronous execution of LLM requests. Users do not need to wait for LLM to finish in real-time â€” they can fetch results later using a job_id.

#### Workflow
1.	Job creation: user sends a request to /chat/async or /chat/rag/async
2.	Job queue: jobs enter a Redis-backed queue respecting rate limits and LLM load
3.	Workers: run as separate processes/containers and process jobs:
- Send request to LLM (OpenAI/Gemini)
- Normalize, filter, and log responses
- Save result/error back to Redis
4.	Heartbeat: workers send periodic heartbeat signals
5.	Fetching results: GET /inference/{job_id} returns:
- status: pending, completed, error
- result (if ready)
- error message (if any)

#### Usage
- Run a worker:
```bash
python -m app.inference.workers.worker_main
```
- Multiple workers can run simultaneously
- Load is balanced via job queue
- Works with rate-limiting to prevent overloading LLM

#### Related Endpoints
- POST /chat/async â€” create async LLM job
- POST /chat/rag/async â€” create async RAG job
- GET /inference/{job_id} â€” fetch job result/status

â¸»

### ğŸ“š Resources
- [OpenAI API Documentation](https://platform.openai.com/docs/api-reference/introduction)
- [Gemini API Documentation](https://ai.google.dev/gemini-api/docs?hl=en)
- [HuggingFace](https://huggingface.co/)
- [Ollama](https://ollama.com)


## Ğ ÑƒÑÑĞºĞ¸Ğ¹

ĞŸÑ€Ğ¾ĞµĞºÑ‚ ai-assistant-api Ğ¿Ğ¾Ğ·Ğ²Ğ¾Ğ»ÑĞµÑ‚ Ğ²Ğ·Ğ°Ğ¸Ğ¼Ğ¾Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ LLM (Large Language Models â€” Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğµ ÑĞ·Ñ‹ĞºĞ¾Ğ²Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸) Ñ‡ĞµÑ€ĞµĞ· API.
ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
- [OpenAI](https://openai.com)
- [Gemini](https://gemini.google.com)

Ğ›Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶Ğ¸Ğ²Ğ°ĞµĞ¼Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸:
[API for Qwen models](https://github.com/onfiiva/qwen3-apis)

- [Ollama](https://ollama.com)
[mistral:7b-instruct-q4_K_M](https://ollama.com/library/mistral:7b-instruct-q4_K_M)
- [Qwen3](https://qwen.ai/)
[Qwen3-4B-VL-Instruct](https://huggingface.co/Qwen/Qwen3-VL-4B-Instruct)
[Qwen3-TTS-12Hz-1.7B-CustomVoice](https://huggingface.co/Qwen/Qwen3-TTS-12Hz-1.7B-CustomVoice)

Ğ¡ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ ÑÑ‚Ğ¾Ğ³Ğ¾ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° Ğ²Ñ‹ Ğ¼Ğ¾Ğ¶ĞµÑ‚Ğµ:
- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹ Ğº LLM (ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾, Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾ Ğ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ°Ğ³ĞµĞ½Ñ‚Ğ°)
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ RAG (retrieval-augmented generation â€” Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ñ Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ĞµĞ¼ Ğ¿Ğ¾Ğ¸ÑĞºĞ°)
- Ğ­ĞºÑĞ¿ĞµÑ€Ğ¸Ğ¼ĞµĞ½Ñ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ñ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ°Ğ¼Ğ¸ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ (temperature, top_p, max_tokens Ğ¸ Ğ´Ñ€.)
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ ÑÑ‚Ğ°Ñ‚ÑƒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ñ‡ĞµÑ€ĞµĞ· Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ API Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- Ğ£Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ‚ÑŒ Ñ‚Ğ°Ğ¹Ğ¼Ğ°ÑƒÑ‚Ğ°Ğ¼Ğ¸ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑ‚ÑŒ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹ Ğ² Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ‚Ğµ JSON Ğ´Ğ»Ñ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ° Ğ¸ Ñ‚ĞµÑÑ‚Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ LLM-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ² Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ¼ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞµ
- Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ½Ñ‹Ğµ/Ğ·Ğ°Ğ¿Ñ€ĞµÑ‰Ñ‘Ğ½Ğ½Ñ‹Ğµ ĞºĞ¾Ğ¼Ğ°Ğ½Ğ´Ñ‹ Ğ¸ Ğ¾Ñ‡Ğ¸Ñ‰Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒÑĞºĞ¸Ğ¹ Ğ²Ğ²Ğ¾Ğ´
- ĞÑ‚ÑĞ»ĞµĞ¶Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ²Ñ€ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ñ‹Ğµ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑÑ‹
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğ½Ğ° Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ/Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ¸ÑÑ‚Ñ€Ğ°Ñ‚Ğ¾Ñ€Ğ°
- Ğ’ÑÑ‚Ñ€Ğ°Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, Ñ…Ñ€Ğ°Ğ½Ğ¸Ñ‚ÑŒ Ğ¸Ñ… Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ¾Ğ¹ Ğ‘Ğ” (Qdrant) Ğ¸ Ğ²Ñ‹Ğ¿Ğ¾Ğ»Ğ½ÑÑ‚ÑŒ ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
- Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ°Ñ‚ÑŒ Ñ Ğ¼Ğ½Ğ¾Ğ³Ğ¾ÑĞ·Ñ‹Ñ‡Ğ½Ñ‹Ğ¼ ĞºĞ¾Ğ½Ñ‚ĞµĞ½Ñ‚Ğ¾Ğ¼ Ğ¸ Ğ±Ğ¾Ğ»ÑŒÑˆĞ¸Ğ¼Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸, Ñ€Ğ°Ğ·Ğ±Ğ¸Ğ²Ğ°Ñ Ğ¸Ñ… Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
- Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ÑŒ Swagger UI Ñ Ğ¿Ğ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ¾Ğ¹ Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ñ‡ĞµÑ€ĞµĞ· JWT
- ĞŸÑ€Ğ¸Ğ¼ĞµĞ½ÑÑ‚ÑŒ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğµ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ° Ñ Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒÑ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹ Ğ¸ Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³Ğ¾Ğ¼ heartbeat
- ĞŸÑ€Ğ¾ÑÑ‚Ğ°Ñ LoRa
- Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ñ‚ÑŒ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ñ‹Ğµ Ñ„Ğ°Ğ¹Ğ»Ñ‹ .wav Ñ Ğ¿Ğ¾Ğ¼Ğ¾Ñ‰ÑŒÑ TTS
- ĞĞ±Ñ€Ğ°Ñ‰Ğ°Ñ‚ÑŒÑÑ Ğº LMService

â¸»

### ğŸ“ Ğ¡Ñ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ° Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
```bash
ai-assistant-api/                         # ĞšĞ¾Ñ€ĞµĞ½ÑŒ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ° AI-Ğ°ÑÑĞ¸ÑÑ‚ĞµĞ½Ñ‚Ğ°
â”œâ”€â”€ api/                                  # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ backend-ÑĞµÑ€Ğ²Ğ¸Ñ (FastAPI)
â”‚   â”œâ”€â”€ alembic/                          # ĞœĞ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¸ Ğ±Ğ°Ğ·Ñ‹ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… (Alembic)
â”‚   â”‚   â”œâ”€â”€ env.py                        # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Alembic, Ğ¿Ğ¾Ğ´ĞºĞ»ÑÑ‡ĞµĞ½Ğ¸Ğµ Ğº Ğ‘Ğ”
â”‚   â”‚   â”œâ”€â”€ README                        # Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ¾ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸ÑĞ¼
â”‚   â”‚   â”œâ”€â”€ script.py.mako                # Ğ¨Ğ°Ğ±Ğ»Ğ¾Ğ½ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ Ñ„Ğ°Ğ¹Ğ»Ğ¾Ğ² Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
â”‚   â”‚   â””â”€â”€ versions/                     # Ğ˜ÑÑ‚Ğ¾Ñ€Ğ¸Ñ Ğ¼Ğ¸Ğ³Ñ€Ğ°Ñ†Ğ¸Ğ¹
â”‚   â”œâ”€â”€ alembic.ini                       # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Alembic (URL Ğ‘Ğ” Ğ¸ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸)
â”‚   â”œâ”€â”€ app/                              # ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¾Ğ¹ ĞºĞ¾Ğ´ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ agents/                       # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° AI-Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² (ReAct, tool-based Ğ¸ Ğ´Ñ€.)
â”‚   â”‚   â”‚   â”œâ”€â”€ actions.py                # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ñ‹Ñ… Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ² (Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ğ°, Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ñ‹ Ğ¸ Ñ‚.Ğ´.)
â”‚   â”‚   â”‚   â”œâ”€â”€ memory/                   # ĞŸĞ¾Ğ´ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base.py               # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ Ğ¸Ğ½Ñ‚ĞµÑ€Ñ„ĞµĞ¹Ñ Ğ¿Ğ°Ğ¼ÑÑ‚Ğ¸
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ in_memory.py          # ĞŸĞ°Ğ¼ÑÑ‚ÑŒ Ğ² Ğ¾Ğ¿ĞµÑ€Ğ°Ñ‚Ğ¸Ğ²ĞºĞµ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis_async.py        # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Redis-Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py              # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Redis-Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ summarize.py          # Ğ¡Ğ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ Ğ´Ğ¸Ğ°Ğ»Ğ¾Ğ³Ğ°
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ vector_memory.py      # Ğ’ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ğ°Ñ Ğ¿Ğ°Ğ¼ÑÑ‚ÑŒ (RAG)
â”‚   â”‚   â”‚   â”œâ”€â”€ react/                    # Ğ ĞµĞ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ ReAct-Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ agent.py              # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° ReAct Ñ†Ğ¸ĞºĞ»Ğ° (Thought â†’ Action â†’ Observation)
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Pydantic-ÑÑ…ĞµĞ¼Ñ‹ Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ summary.py            # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ ÑÑƒĞ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ state.py                  # Ğ¥Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ ÑĞ¾ÑÑ‚Ğ¾ÑĞ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚   â””â”€â”€ tools/                    # Ğ˜Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹, ĞºĞ¾Ñ‚Ğ¾Ñ€Ñ‹Ğ¼Ğ¸ Ğ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ°Ğ³ĞµĞ½Ñ‚
â”‚   â”‚   â”‚       â”œâ”€â”€ __init__.py           # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ğ°ĞºĞµÑ‚Ğ° tools
â”‚   â”‚   â”‚       â”œâ”€â”€ actions/execute.py    # Ğ˜ÑĞ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ¸Ğµ Ğ´ĞµĞ¹ÑÑ‚Ğ²Ğ¸Ğ¹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚       â”œâ”€â”€ base.py               # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğ¹ ĞºĞ»Ğ°ÑÑ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚       â”œâ”€â”€ external_api.py       # Ğ’Ñ‹Ğ·Ğ¾Ğ²Ñ‹ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… API
â”‚   â”‚   â”‚       â”œâ”€â”€ registry.py           # Ğ ĞµĞµÑÑ‚Ñ€ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”‚       â”œâ”€â”€ search.py             # ĞŸĞ¾Ğ¸ÑĞº (Ğ»Ğ¾ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ / Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹)
â”‚   â”‚   â”‚       â”œâ”€â”€ summary.py            # Ğ¡Ğ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â”‚       â”œâ”€â”€ validation.py         # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ°
â”‚   â”‚   â”‚       â”œâ”€â”€ vector_search_async.py# ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
â”‚   â”‚   â”‚       â””â”€â”€ vector_search.py      # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº
â”‚   â”‚   â”œâ”€â”€ api/                          # HTTP-ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹ FastAPI
â”‚   â”‚   â”‚   â”œâ”€â”€ agents.py                 # API Ğ´Ğ»Ñ Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‹ Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°Ğ¼Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                   # ĞĞ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¸ Ğ°ÑƒÑ‚ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ
â”‚   â”‚   â”‚   â”œâ”€â”€ chat.py                   # Ğ¡Ğ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_async.py             # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚
â”‚   â”‚   â”‚   â”œâ”€â”€ embeddings.py             # Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py              # Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ inference endpoint
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py              # Ğ—Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° Ğ¸ Ğ¸Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â”‚   â”œâ”€â”€ instruction_tuning.py     # Fine-tuning / instruction tuning
â”‚   â”‚   â”‚   â”œâ”€â”€ lmstudio.py               # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ LM Studio
â”‚   â”‚   â”‚   â”œâ”€â”€ search.py                 # API Ğ¿Ğ¾Ğ¸ÑĞºĞ°
â”‚   â”‚   â”‚   â”œâ”€â”€ smart_chat.py             # Ğ£Ğ¼Ğ½Ñ‹Ğ¹ Ğ¾Ñ€ĞºĞµÑÑ‚Ñ€Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ Ñ‡Ğ°Ñ‚
â”‚   â”‚   â”‚   â””â”€â”€ tts.py                    # Text-to-Speech endpoint
â”‚   â”‚   â”œâ”€â”€ container.py                  # Dependency Injection ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€
â”‚   â”‚   â”œâ”€â”€ core/                         # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ğ°Ñ Ğ¸Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ğ°Ñ ĞºĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # Ğ“Ğ»Ğ¾Ğ±Ğ°Ğ»ÑŒĞ½Ñ‹Ğµ Ğ½Ğ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ¸ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”‚   â”œâ”€â”€ logging.py                # ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Ğ»Ğ¾Ğ³Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ñ
â”‚   â”‚   â”‚   â”œâ”€â”€ redis.py                  # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Redis
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py               # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ, Ñ…ÑÑˆĞ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ, ÑˆĞ¸Ñ„Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
â”‚   â”‚   â”‚   â”œâ”€â”€ timing.py                 # Ğ£Ñ‚Ğ¸Ğ»Ğ¸Ñ‚Ñ‹ Ğ·Ğ°Ğ¼ĞµÑ€Ğ° Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ tokens.py                 # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ñ‚Ğ¾ĞºĞµĞ½Ğ°Ğ¼Ğ¸ (LLM usage)
â”‚   â”‚   â”‚   â””â”€â”€ vault.py                  # Ğ˜Ğ½Ñ‚ĞµĞ³Ñ€Ğ°Ñ†Ğ¸Ñ Ñ ÑĞµĞºÑ€ĞµÑ‚-Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼
â”‚   â”‚   â”œâ”€â”€ dependencies/                 # FastAPI dependencies
â”‚   â”‚   â”‚   â”œâ”€â”€ agent_params.py           # ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ñ‹ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸Ğ· Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ°
â”‚   â”‚   â”‚   â”œâ”€â”€ auth.py                   # Dependency Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ inference.py              # Dependency Ğ´Ğ»Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
â”‚   â”‚   â”‚   â”œâ”€â”€ rate_limit.py             # ĞĞ³Ñ€Ğ°Ğ½Ğ¸Ñ‡ĞµĞ½Ğ¸Ğµ Ñ‡Ğ°ÑÑ‚Ğ¾Ñ‚Ñ‹ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ security.py               # ĞŸÑ€Ğ¾Ğ²ĞµÑ€ĞºĞ¸ Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ user.py                   # ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
â”‚   â”‚   â”‚   â””â”€â”€ validation.py             # ĞĞ±Ñ‰Ğ°Ñ Ğ²Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ†Ğ¸Ñ
â”‚   â”‚   â”œâ”€â”€ embeddings/                   # ĞŸĞ¾Ğ´ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ clients/                  # ĞšĞ»Ğ¸ĞµĞ½Ñ‚Ñ‹ Ğ²Ğ½ĞµÑˆĞ½Ğ¸Ñ… embedding-Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py                # Ğ¤Ğ°Ğ±Ñ€Ğ¸ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ embedding-ĞºĞ»Ğ¸ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ schemas.py                # Ğ¡Ñ…ĞµĞ¼Ñ‹ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ service.py                # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ similarity.py             # Ğ Ğ°ÑÑ‡Ñ‘Ñ‚ similarity
â”‚   â”‚   â”‚   â””â”€â”€ vector_store.py           # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½Ñ‹Ğ¼ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼
â”‚   â”‚   â”œâ”€â”€ inference/                    # ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ°Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° LLM-Ğ·Ğ°Ğ´Ğ°Ñ‡
â”‚   â”‚   â”‚   â”œâ”€â”€ inference_repository.py   # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ñ…Ñ€Ğ°Ğ½Ğ¸Ğ»Ğ¸Ñ‰ĞµĞ¼ Ğ·Ğ°Ğ´Ğ°Ñ‡
â”‚   â”‚   â”‚   â”œâ”€â”€ inference_service.py      # Ğ¡ĞµÑ€Ğ²Ğ¸Ñ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ° Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
â”‚   â”‚   â”‚   â””â”€â”€ workers/                  # Ğ’Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡
â”‚   â”‚   â”‚       â”œâ”€â”€ async_inference_worker.py
â”‚   â”‚   â”‚       â”œâ”€â”€ inference_worker.py
â”‚   â”‚   â”‚       â”œâ”€â”€ worker_main.py        # Ğ¢Ğ¾Ñ‡ĞºĞ° Ğ²Ñ…Ğ¾Ğ´Ğ° Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°
â”‚   â”‚   â”‚       â””â”€â”€ job_handler/          # ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚Ñ‡Ğ¸ĞºĞ¸ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ñ‚Ğ¸Ğ¿Ğ¾Ğ² Ğ·Ğ°Ğ´Ğ°Ñ‡
â”‚   â”‚   â”œâ”€â”€ infra/                        # Ğ˜Ğ½Ñ„Ñ€Ğ°ÑÑ‚Ñ€ÑƒĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğ¹ ÑĞ»Ğ¾Ğ¹
â”‚   â”‚   â”‚   â”œâ”€â”€ chunker.py                # Ğ Ğ°Ğ·Ğ±Ğ¸ĞµĞ½Ğ¸Ğµ Ñ‚ĞµĞºÑÑ‚Ğ° Ğ½Ğ° Ñ‡Ğ°Ğ½ĞºĞ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_loader.py             # ĞŸĞ°Ñ€ÑĞ¸Ğ½Ğ³ PDF
â”‚   â”‚   â”‚   â””â”€â”€ db/                       # Ğ Ğ°Ğ±Ğ¾Ñ‚Ğ° Ñ Ğ‘Ğ”
â”‚   â”‚   â”œâ”€â”€ llm/                          # Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ LLM-ÑĞ»Ğ¾Ğ¹
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/                 # ĞĞ´Ğ°Ğ¿Ñ‚ĞµÑ€Ñ‹ Ñ€Ğ°Ğ·Ğ½Ñ‹Ñ… Ğ¿Ñ€Ğ¾Ğ²Ğ°Ğ¹Ğ´ĞµÑ€Ğ¾Ğ²
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ base/                 # Ğ‘Ğ°Ğ·Ğ¾Ğ²Ñ‹Ğµ Ğ°Ğ±ÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ğ¸ (generation, embedding, tts)
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ geminiAdapter.py      # Google Gemini
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ LMStudioAdapter.py    # LM Studio
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ollamaAdapter.py      # Ollama
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ openAIAdapter.py      # OpenAI
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ qwen3TTSAdapter.py    # Qwen TTS
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ qwen3vlAdapter.py     # Qwen3-VL (vision-language)
â”‚   â”‚   â”‚   â”œâ”€â”€ config.py                 # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ factory.py                # Ğ¤Ğ°Ğ±Ñ€Ğ¸ĞºĞ° ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ñ LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ filter.py                 # Ğ¤Ğ¸Ğ»ÑŒÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²
â”‚   â”‚   â”‚   â”œâ”€â”€ normalizer.py             # ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ²Ñ…Ğ¾Ğ´Ğ½Ñ‹Ñ… Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â”‚   â”œâ”€â”€ runner.py                 # Ğ£Ğ½Ğ¸Ğ²ĞµÑ€ÑĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ Ğ·Ğ°Ğ¿ÑƒÑĞº LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ sanitizer.py              # Ğ‘ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ (prompt sanitation)
â”‚   â”‚   â”‚   â””â”€â”€ schemas.py                # Ğ¡Ñ…ĞµĞ¼Ñ‹ LLM-Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ²/Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ middlewares/                  # Middleware FastAPI
â”‚   â”‚   â”œâ”€â”€ models/user.py                # ORM Ğ¼Ğ¾Ğ´ĞµĞ»ÑŒ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ
â”‚   â”‚   â”œâ”€â”€ schemas/                      # Pydantic-ÑÑ…ĞµĞ¼Ñ‹ API
â”‚   â”‚   â”œâ”€â”€ services/                     # Ğ‘Ğ¸Ğ·Ğ½ĞµÑ-Ğ»Ğ¾Ğ³Ğ¸ĞºĞ° Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â”‚   â”œâ”€â”€ auth_service.py           # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ğ°Ğ²Ñ‚Ğ¾Ñ€Ğ¸Ğ·Ğ°Ñ†Ğ¸Ğ¸
â”‚   â”‚   â”‚   â”œâ”€â”€ chat_service.py           # Ğ›Ğ¾Ğ³Ğ¸ĞºĞ° Ñ‡Ğ°Ñ‚Ğ°
â”‚   â”‚   â”‚   â”œâ”€â”€ ingestion.py              # Ğ˜Ğ½Ğ´ĞµĞºÑĞ°Ñ†Ğ¸Ñ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…
â”‚   â”‚   â”‚   â”œâ”€â”€ rag_service.py            # Retrieval-Augmented Generation
â”‚   â”‚   â”‚   â”œâ”€â”€ tts_service.py            # Text-to-Speech Ğ»Ğ¾Ğ³Ğ¸ĞºĞ°
â”‚   â”‚   â”‚   â””â”€â”€ orchestration/            # ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ LLM Ğ¸ Ğ°Ğ³ĞµĞ½Ñ‚Ğ¾Ğ²
â”‚   â”‚   â”œâ”€â”€ startup.py                    # Ğ˜Ğ½Ğ¸Ñ†Ğ¸Ğ°Ğ»Ğ¸Ğ·Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¸Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ñ
â”‚   â”‚   â””â”€â”€ validators/                   # Ğ’Ğ°Ğ»Ğ¸Ğ´Ğ°Ñ‚Ğ¾Ñ€Ñ‹ Ğ¿Ğ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¾Ğ²
â”‚   â”œâ”€â”€ Dockerfile                        # Docker-Ğ¾Ğ±Ñ€Ğ°Ğ· API ÑĞµÑ€Ğ²Ğ¸ÑĞ°
â”‚   â”œâ”€â”€ prometheus.yaml                   # ĞšĞ¾Ğ½Ñ„Ğ¸Ğ³ÑƒÑ€Ğ°Ñ†Ğ¸Ñ Ğ¼ĞµÑ‚Ñ€Ğ¸Ğº Prometheus
â”‚   â”œâ”€â”€ reflection.md                     # ĞÑ€Ñ…Ğ¸Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ½Ñ‹Ğµ Ğ·Ğ°Ğ¼ĞµÑ‚ĞºĞ¸
â”‚   â””â”€â”€ requirements.txt                  # Python-Ğ·Ğ°Ğ²Ğ¸ÑĞ¸Ğ¼Ğ¾ÑÑ‚Ğ¸
â”œâ”€â”€ docker-compose.yaml                   # ĞÑ€ĞºĞµÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ ÑĞµÑ€Ğ²Ğ¸ÑĞ¾Ğ² (API, Ğ‘Ğ”, Redis Ğ¸ Ñ‚.Ğ´.)
â””â”€â”€ README.md                             # ĞĞ±Ñ‰Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Ğ¿Ñ€Ğ¾ĞµĞºÑ‚Ğ°
```
â¸»

### ğŸ³ Docker: ÑƒÑÑ‚Ğ°Ğ½Ğ¾Ğ²ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº

1.	Ğ¡Ğ±Ğ¾Ñ€ĞºĞ° Ğ¸ Ğ·Ğ°Ğ¿ÑƒÑĞº ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ğ¾Ğ²:
```bash
docker-compose up --build
```
2.	API Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¾ Ğ¿Ğ¾ Ğ°Ğ´Ñ€ĞµÑÑƒ:
```
http://127.0.0.1:8000
```
3.	Swagger UI:
```
http://127.0.0.1:8000/docs
```
4.	ĞĞ°ÑÑ‚Ñ€Ğ¾Ğ¹ĞºĞ° Vault KV:
```bash
export VAULT_ADDR=http://127.0.0.1:8200
export VAULT_TOKEN=root
vault kv put secret/ai-assistant-api \
  JWT_SECRET_KEY="somesecret" \
  OPENAI_API_KEY="somekey" \
  GEMINI_API_KEY="somekey" \
  OLLAMA_BASE_URL="http://host.docker.internal:11434" \
  QWEN3_VL_BASE_URL="http://host.docker.internal:8000" \
  QWEN_TTS_BASE_URL="http://host.docker.internal:8000" \
  TTS_API_URL="http://host.docker.internal:9000" \
  LMSTUDIO_BASE_URL="https://lsstudio.monti215.ru/" \
  LMSTUDIO_API_KEY="sk-lm-JvooJLfY:rhAqs2DhJudo0L2DIh3D" \
  ALLOWED_PROVIDERS='["openai","gemini","ollama","qwen-tts","lmstudio"]' \
  FORBIDDEN_COMMANDS='["rm -rf", "shutdown", "docker stop"]' \
  ROOT_USR_PASS="somepass" \
  INSTRUCTION_PATTERNS='["ignore previous","follow these steps","you must","act as","pretend you are","roleplay","system prompt","developer message","internal instructions"]' \
  EXFILTRATION_PATTERNS='["what are your instructions","show system prompt","reveal context","print everything you know","dump input","debug output"]' \
  FORBIDDEN_LLM_OUTPUT='["as a system","internal instructions","developer message"]' \
  INSTRUCTION_REGEX='["\\byou must\\b","\\byou should\\b","\\byou are\\b","\\bact as\\b","\\bpretend you are\\b","\\bfollow these\\b","\\bignore\\b.+\\b(instruction|rule|above|previous)\\b"]' \
  ROLE_OVERRIDE_REGEX='["\\bas a system\\b","\\bas an ai\\b","\\bas chatgpt\\b","\\bas gemini\\b","\\byour role is\\b","\\byou are no longer\\b","\\bdeveloper mode\\b","\\bdan\\b"]' \
  META_SYSTEM_REGEX='["\\bsystem prompt\\b","\\binternal instructions\\b","\\bdeveloper message\\b","\\bhidden rules\\b","\\bwhat are your instructions\\b","\\bshow.*prompt\\b"]' \
  MAX_PROMPT_LENGTH=2048 \
  MAX_RESPONSE_LENGTH=2048
```
â¸»

### ğŸ”‘ ĞŸĞµÑ€ĞµĞ¼ĞµĞ½Ğ½Ñ‹Ğµ Ğ¾ĞºÑ€ÑƒĞ¶ĞµĞ½Ğ¸Ñ (.env)
```env
DEFAULT_PROVIDER=gemini
EMBEDDING_PROVIDER=gemini
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
DATABASE_URL=postgresql+asyncpg://rag:rag@rag-postgres:5432/rag
DB_HOST=localhost
DB_USER=rag
DB_PASS=rag
DB_NAME=rag
QDRANT_URL=http://db-qdrant:6333
RATE_LIMIT_USER_REQUESTS=5
RATE_LIMIT_ADMIN_REQUESTS=10
RATE_LIMIT_WINDOW=60
JWT_SECRET_KEY=root
VAULT_ADDR=http://localhost:8200
VAULT_TOKEN=root
DEBUG_MODE=True
MAX_EMBED_CHUNKS=60
MAX_EMBED_TOKENS=40000
MAX_CHUNK_TOKENS=512
```
â¸»

### ğŸ’¡ Ğ­Ğ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹

#### /auth
- POST /auth/login â€” Ğ»Ğ¾Ğ³Ğ¸Ğ½ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT
- POST /auth/register â€” Ñ€ĞµĞ³Ğ¸ÑÑ‚Ñ€Ğ°Ñ†Ğ¸Ñ Ğ½Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ (Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ°Ğ´Ğ¼Ğ¸Ğ½Ğ°) Ğ¸ Ğ²Ñ‹Ğ´Ğ°Ñ‡Ğ° JWT

#### /chat
- POST /chat/ â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM
- POST /chat/rag â€” ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG
- POST /chat/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² LLM, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- POST /chat/rag/async â€” Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ñ‹Ğ·Ğ¾Ğ² RAG, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id

#### /agents
- POST /agents/run â€” Ğ·Ğ°Ğ¿ÑƒÑĞº Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ñ Ñ†ĞµĞ»ÑŒÑ, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ job_id
- GET /agents/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ° Ğ¸ Ğ¸ÑÑ‚Ğ¾Ñ€Ğ¸Ğ¸ ÑˆĞ°Ğ³Ğ¾Ğ²
- GET /agents/tools â€” ÑĞ¿Ğ¸ÑĞ¾Ğº Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ñ… Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ´Ğ»Ñ Ğ°Ğ³ĞµĞ½Ñ‚Ğ°

#### /embeddings
- POST /embeddings/search â€” ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡ĞµÑĞºĞ¸Ğ¹ Ğ¿Ğ¾Ğ¸ÑĞº, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²

#### /ingestion
- POST /ingestion/ingest â€” Ğ·Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ° PDF-Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ¾Ğ² Ğ² Ğ²ĞµĞºÑ‚Ğ¾Ñ€Ğ½ÑƒÑ Ğ‘Ğ” Ñ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼Ğ¸

#### /search
- GET /search/ â€” Ğ¿Ğ¾Ğ¸ÑĞº Ğ¿Ğ¾ Ğ·Ğ°Ğ³Ñ€ÑƒĞ¶ĞµĞ½Ğ½Ñ‹Ğ¼ ÑĞ¼Ğ±ĞµĞ´Ğ´Ğ¸Ğ½Ğ³Ğ°Ğ¼, Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ top-k ÑĞ¾Ğ²Ğ¿Ğ°Ğ´ĞµĞ½Ğ¸Ğ¹

#### /inference
- POST /inference/ â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ¸ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/Ğ¾ÑˆĞ¸Ğ±ĞºĞ¸ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

#### /tts
- POST / â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ³Ğ¾Ğ»Ğ¾ÑĞ¾Ğ²Ğ¾Ğ³Ğ¾ .wav Ñ„Ğ°Ğ¹Ğ»Ğ° Ğ´Ğ»Ñ ÑĞºĞ°Ñ‡Ğ¸Ğ²Ğ°Ğ½Ğ¸Ñ

#### /lmstudio
- GET /models/ â€” Ğ½Ğ°Ğ¹Ñ‚Ğ¸ Ğ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ñ‹Ğµ Ğ¼Ğ¾Ğ´ĞµĞ»Ğ¸ LMStudio

â¸»

### âš™ï¸ ĞÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ğ¹ Ğ²Ğ¾Ñ€ĞºĞµÑ€ Ğ¸Ğ½Ñ„ĞµÑ€ĞµĞ½ÑĞ°

#### ĞĞ°Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ¸Ğµ:
ĞĞ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ñ‹Ñ… Ğ·Ğ°Ğ¿Ñ€Ğ¾ÑĞ¾Ğ² Ğº LLM. ĞŸĞ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»Ñ Ğ½Ğµ Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¶Ğ´Ğ°Ñ‚ÑŒ Ğ·Ğ°Ğ²ĞµÑ€ÑˆĞµĞ½Ğ¸Ñ LLM Ğ² Ñ€ĞµĞ°Ğ»ÑŒĞ½Ğ¾Ğ¼ Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ¸ â€” Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚ Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾Ğ·Ğ¶Ğµ Ğ¿Ğ¾ job_id.

#### Workflow
1.	Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ: Ğ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ñ‚ĞµĞ»ÑŒ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑĞµÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğ² /chat/async Ğ¸Ğ»Ğ¸ /chat/rag/async
2.	ĞÑ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹: Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ Ğ¿Ğ¾ÑÑ‚ÑƒĞ¿Ğ°ÑÑ‚ Ğ² Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ½Ğ° Redis Ñ ÑƒÑ‡Ñ‘Ñ‚Ğ¾Ğ¼ Ğ»Ğ¸Ğ¼Ğ¸Ñ‚Ğ¾Ğ² Ğ¸ Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ğ½Ğ° LLM
3.	Ğ’Ğ¾Ñ€ĞºĞµÑ€Ñ‹: Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ÑÑ‚ÑÑ ĞºĞ°Ğº Ğ¾Ñ‚Ğ´ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑÑ‹/ĞºĞ¾Ğ½Ñ‚ĞµĞ¹Ğ½ĞµÑ€Ñ‹ Ğ¸ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ°Ñ‚Ñ‹Ğ²Ğ°ÑÑ‚ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ:

- ĞÑ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ·Ğ°Ğ¿Ñ€Ğ¾Ñ Ğº LLM (OpenAI/Gemini)
- ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ğ¸Ğ·ÑƒÑÑ‚, Ñ„Ğ¸Ğ»ÑŒÑ‚Ñ€ÑƒÑÑ‚ Ğ¸ Ğ»Ğ¾Ğ³Ğ¸Ñ€ÑƒÑÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚Ñ‹
- Ğ¡Ğ¾Ñ…Ñ€Ğ°Ğ½ÑÑÑ‚ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚/Ğ¾ÑˆĞ¸Ğ±ĞºÑƒ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ½Ğ¾ Ğ² Redis

4.	Heartbeat: Ğ²Ğ¾Ñ€ĞºĞµÑ€Ñ‹ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑÑ‚ Ğ¿ĞµÑ€Ğ¸Ğ¾Ğ´Ğ¸Ñ‡ĞµÑĞºĞ¸Ğµ ÑĞ¸Ğ³Ğ½Ğ°Ğ»Ñ‹ heartbeat
5.	ĞŸĞ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ¾Ğ²: GET /inference/{job_id} Ğ²Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚:

- status: pending, completed, error
- result (ĞµÑĞ»Ğ¸ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¾)
- error message (ĞµÑĞ»Ğ¸ ĞµÑÑ‚ÑŒ)

#### Ğ˜ÑĞ¿Ğ¾Ğ»ÑŒĞ·Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ
- Ğ—Ğ°Ğ¿ÑƒÑĞº Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ°:
```bash
python -m app.inference.workers.worker_main
```
- ĞœĞ¾Ğ¶Ğ½Ğ¾ Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°Ñ‚ÑŒ Ğ½ĞµÑĞºĞ¾Ğ»ÑŒĞºĞ¾ Ğ²Ğ¾Ñ€ĞºĞµÑ€Ğ¾Ğ² Ğ¾Ğ´Ğ½Ğ¾Ğ²Ñ€ĞµĞ¼ĞµĞ½Ğ½Ğ¾
- Ğ‘Ğ°Ğ»Ğ°Ğ½ÑĞ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ½Ğ°Ğ³Ñ€ÑƒĞ·ĞºĞ¸ Ñ‡ĞµÑ€ĞµĞ· Ğ¾Ñ‡ĞµÑ€ĞµĞ´ÑŒ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ğ¹
- ĞŸĞ¾Ğ´Ğ´ĞµÑ€Ğ¶ĞºĞ° rate-limiting Ğ´Ğ»Ñ Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ñ Ğ¿ĞµÑ€ĞµĞ³Ñ€ÑƒĞ·ĞºĞ¸ LLM

#### Ğ¡Ğ²ÑĞ·Ğ°Ğ½Ğ½Ñ‹Ğµ ÑĞ½Ğ´Ğ¿Ğ¾Ğ¸Ğ½Ñ‚Ñ‹
- POST /chat/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ LLM
- POST /chat/rag/async â€” ÑĞ¾Ğ·Ğ´Ğ°Ğ½Ğ¸Ğµ Ğ°ÑĞ¸Ğ½Ñ…Ñ€Ğ¾Ğ½Ğ½Ğ¾Ğ³Ğ¾ Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ RAG
- GET /inference/{job_id} â€” Ğ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ¸Ğµ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚Ğ°/ÑÑ‚Ğ°Ñ‚ÑƒÑĞ° Ğ·Ğ°Ğ´Ğ°Ğ½Ğ¸Ñ

â¸»

#### ğŸ“š Ğ ĞµÑÑƒÑ€ÑÑ‹
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ OpenAI API](https://platform.openai.com/docs/api-reference/introduction)
- [Ğ”Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ğ°Ñ†Ğ¸Ñ Gemini API](https://ai.google.dev/gemini-api/docs?hl=ru)
- [HuggingFace](https://huggingface.co/)
- [Ollama](https://ollama.com)